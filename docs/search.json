[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Community detection tutorial",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Community detection tutorial",
    "section": "Description",
    "text": "Description\nThis is a modeling tutorial for the supplement for Miller-ter Kuile et al. “Accounting for imperfect detection to reveal the importance of current and past environmental conditions for community stability”. in revision\nThe purpose of this tutorial is to provide a detailed description of the modeling approaches used in the paper along with examples of the models in action on both simulated and real datasets."
  },
  {
    "objectID": "index.html#case-studies",
    "href": "index.html#case-studies",
    "title": "Community detection tutorial",
    "section": "Case studies",
    "text": "Case studies\n[describe four datasets here]",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html",
    "href": "01_accounting-for-imperfect-detection.html",
    "title": "1  Accounting for imperfect detection",
    "section": "",
    "text": "Accounting for imperfect detection using Bayesian multi-species model (for either count or detection/non-detection)\n[look in supporting info for more]"
  },
  {
    "objectID": "02_computing-indices.html",
    "href": "02_computing-indices.html",
    "title": "2  Computing indices of community stability",
    "section": "",
    "text": "Measured community change (“stability”) through time\nchange in species presence/absence\nor change in BC dissimilarity\ncalculated posterior means and SD values for each change metric for each site and year\nused posterior means and standard deviation values in part 3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Computing indices of community stability</span>"
    ]
  },
  {
    "objectID": "03_community-stability-environment.html",
    "href": "03_community-stability-environment.html",
    "title": "3  Evaluating community stability in relation to environmental variables",
    "section": "",
    "text": "compiled abiotic and biotic variables that could influence community change\nDetermine whether responses to abiotic and biotic factors are instantaneous or lagged using Bayesian regression with stochastic antecedent modeling\nmodel structure",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Evaluating community stability in relation to environmental variables</span>"
    ]
  },
  {
    "objectID": "04_imperfect-detection.html",
    "href": "04_imperfect-detection.html",
    "title": "4  How imperfect detection shapes community change estimates across datasets",
    "section": "",
    "text": "assessed how accounting for imperfect detection influenced estimates of community change by comparing observed and modeled estimates of dissimilarity\nfirst creating observed dataset based on multiple sampling events per year\nthen created an observed dataset based on one sampling event per year\nexamined differences between observed datasets by using Bayesian hierarchical regression with change as response and data derivation crossed with dataset as predictor\npost-hoc pairwise tests to determine direction and magnitude of differences",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>How imperfect detection shapes community change estimates across datasets</span>"
    ]
  },
  {
    "objectID": "index.html#tools-youll-need",
    "href": "index.html#tools-youll-need",
    "title": "Community detection tutorial",
    "section": "Tools you’ll need",
    "text": "Tools you’ll need\nAll models are Bayesian models run in R and JAGS. You will need these programs to run these models.\nDownload R\n(We also recommend RStudio)\nDownload JAGS"
  },
  {
    "objectID": "index.html#outline",
    "href": "index.html#outline",
    "title": "Community detection tutorial",
    "section": "Outline",
    "text": "Outline\nIn the following pages, we will walk you through the model formulation as well as model code demonstrating the modeling framework."
  },
  {
    "objectID": "index.html#model-description",
    "href": "index.html#model-description",
    "title": "Community detection tutorial",
    "section": "Model description",
    "text": "Model description\nWe employed a two-step modeling process (Figure 1).\n ### A) Multi-species model accounting for imperfect detection\nThis model links observed abundance or presence-absence of species in a community to detection probabilities to generate a latent “true” abundance or occupancy for each species in each site in each year. We used this model to then generate metrics of community change (beta diversity). We built these models based on previous model developments for accounting for imperfect detection in community datasets (Dorazio et al. 2006).\n\nB) Regression model with environmental covariates\nThis model incorporates mean and variance of community change metrics from the model in A) into a regression examining the effects of environmental covariates on community change. This model employs a stochastic antecedent modeling (SAM) framework (Ogle et al. 2015) to allow environmental covariates to have immediate and lagged responses."
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html#model-formulation",
    "href": "01_accounting-for-imperfect-detection.html#model-formulation",
    "title": "1  Accounting for imperfect detection",
    "section": "1.1 Model Formulation",
    "text": "1.1 Model Formulation\nTraditional multi-species abundance (MSAM) and occupancy (MSOM) models are built on several data requirements and assumptions:\n\nSites are visited more than once within a year, so that repeat visits can be used to estimate detection probabilities.\nThere is “closure” within a year at a site, which means species are neither gained or lost from a site within that year.\n\nThese models have two components, including a) a biological process linking latent “true” abundance or occupancy to an expected value or probability, which could depend on covariates and b) an observation process linking observed data to detection probability and “true” abundance or occupancy.\n\n1.1.1 Data distribution\nIn all following mathematical descriptions and models, subscripts are as follows:\n\ns : species\nt : survey unit (e.g., transect, quadrat)\ny : year\nr : survey replicate\n\nFor abundance models, observed data, \\(y_{s,t,y,r}\\), is dependent on detection probability, \\(p_{s,t,y,r}\\), and “true” latent abundance, \\(N_{s,t,y}\\):\n\\(y_{s,t,y,r} \\sim Binomial(p_{s,t,y,r}, N_{s,t,y})\\)\nFor occupancy models, observed data, \\(y_{s,t,y,r}\\), is dependent on detection probability, \\(p_{s,t,y,r}\\), and “true” latent occupancy, \\(z_{s,t,y}\\) (\\(z_{s,t,y}\\) = 1: presence; \\(z_{s,t,y}\\) = 0: absence):\n\\(y_{s,t,y,r} \\sim Bernoulli(p_{s,t,y,r}* z_{s,t,y})\\)\n\n\n1.1.2 Biological process\nFor abundance models, latent abundance, \\(N_{s,t,y}\\), is dependent on a rate parameter \\(\\lambda_{s,t,y}\\):\n\\(N_{s,t,y} \\sim Poisson(\\lambda_{s,t,y})\\)\nWhich, in our models, is dependent on a regression that includes a species-specific intercept and random effects of site within species and year within species which are made identifiable based on the post-sweeping method described in Ogle and Barber (2020):\n\\(log(\\lambda_{s,t,y}) = \\beta_{0s} + \\epsilon_{s,t} + \\gamma_{s,y}\\)\nSimilarly, for occupancy models, \\(z_{s,t,y}\\) is dependent on occupancy probability, \\(\\psi_{s,t,y}\\):\n\\(z_{s,t,y} \\sim Bernoulli(psi_{s,t,y})\\)\nWhich is dependent on a similar regression:\n\\(logit(\\psi_{s,t,y}) = \\beta_{0s} + \\epsilon_{s,t} + \\gamma_{s,y}\\)\nAll species-level intercept values receive priors centered around community-level hyperparameters:\n\\(\\beta_{0s} \\sim Normal(\\mu_\\beta, \\sigma_\\beta)\\)\nWith vague or relatively uninformative priors:\n\\(\\mu_\\beta \\sim Normal(0, 1000)\\)\n\\(\\sigma_\\beta \\sim Uniform(0, 50)\\)\n\n\n1.1.3 Observation process\nFor both abundance and occupancy models, the observation process estimates detection probabilities, \\(p_{s,t,y,r}\\), which can be estimated based on a regression:\n\\(logit(p_{s,t,y,r}) = \\alpha_{0s} + \\sum_{j=1}^{J}\\alpha_jX_{j,s,t,y,r}\\)\nWhere \\(\\alpha_{0s}\\) is a species-level intercept and the coefficients \\(\\alpha_1\\), \\(\\alpha_2\\)… \\(\\alpha_J\\) denote the effect of each detection covariate \\(X_{j,s,t,y,r}\\) for j = 1, 2, … J. Each detection covariate, \\(X_{j,s,t,y,r}\\), can depend on any combination of species, site, year, and replicate (e.g., species traits would be an \\(X_s\\) whereas conditions during a survey might be a \\(X_{t,y,r}\\)).\nAgain, all species-level intercept values receive priors centered around community-level hyperparameters:\n\\(\\alpha_{0s} \\sim Normal(\\mu_\\alpha, \\sigma_\\alpha)\\)\nWith vague or relatively uninformative priors:\n\\(\\mu_\\alpha \\sim Normal(0, 1000)\\)\n\\(\\sigma_\\alpha \\sim Uniform(0, 50)\\)\nAll continous covariate effects got relatively uninformative priors\n\\(\\alpha_j \\sim Normal(0, 1000)\\)\nAnd categorical covariate effects were cell-referenced with the baseline level being that with the most observations (baseline level gets a prior value = 0, all others get uninformative normal priors similar to \\(alpha_j\\), above).\n\n\n1.1.4 The model translated to JAGS code\nBelow is example JAGS code for the model specified above:\n\nmodel{\n  \n  #Example MSAM model for tutorial with simulated data\n  \n  \n  for(s in 1:n.species){ #species\n    for(t in 1:n.transects){ #transects\n      for(y in n.start[t]:n.end[t]){ #years\n        #setting these start and end years to depend on transect\n        #allows them to vary by transect\n        \n        #BIOLOGICAL MODEL \n        \n        #expected number of individuals of species s\n        #in site t in time y is dependent on \n        #a rate parameter, lambda, for a poisson distribution\n        N[s,t,y] ~ dpois(lambda[s,t,y])\n        \n        #this rate parameter is dependent on a regression\n        #with a species intercept,\n        #and species within site, and species within year \n        #random effects (post-sweeping code is below for this )\n        log(lambda[s,t,y]) &lt;- b0.species[s] + \n          eps.site[Site.ID[t], s] +\n          eps.year[Year.ID[y], s]\n        \n        for(r in 1:n.rep[t,y]){ #for the number of surveys on each transect\n          #in each year\n          \n          # OBSERVATION MODEL\n          \n          #detection probability for species s in site t in\n          #year y in replicate r\n          logit(p[s,t,y,r]) &lt;- a0[s] + #species-level intercept\n            #a covariate that is related to the survey \n            #(e.g., weather, survey length)\n            #dependent on site, year, and replicate, but not species\n            a1*survey.covariate[t,y,r] #+\n          #could also add species covariates \n          #(e.g., body size, color, call frequency)\n            #a2*species.covariate[s]\n          \n          #abundance is binomial based on detection probability\n          #and total true abundance at the site\n          y[s,t,y,r] ~ dbin(p[s,t,y,r], N[s,t,y])\n          \n          #create replicate data based on model estimation to\n          #look at goodness-of-fit (regress y.rep ~ y)\n          y.rep[s,t,y,r] ~ dbin(p[s,t,y,r], N[s,t,y])\n          \n        }\n      }\n    }\n    \n    #SPECIES-LEVEL PRIORS:\n    #Detection intercept and slopes for each species\n    #are centered on community-level hyperpriors\n    a0[s] ~ dnorm(mu.a0,tau.a0)\n    \n    #\"baseline\" detection at vis = 0 and size = 0 \n    #on standardized scale\n    p0[s] &lt;- ilogit(a0[s])\n    \n    #species-level intercept - \n    #currently non-identifiable:\n    b0.species[s] ~ dnorm(mu.b0species, tau.b0species)\n    \n    #compute the identifiable species-level intercept:\n    #TRACK THIS ONE for convergence\n    b0.star[s] &lt;- b0.species[s] + ave.eps.site[s] + ave.eps.year[s]\n    \n  }\n  \n  #SITE W/IN SPECIES RANDOM EFFECTS\n  #sites nested within species (sites sum to zero w/in each species)\n  for(s in 1:n.species){\n    for(t in 1:n.sites){\n      #non-identifiable random effect\n      eps.site[t,s] ~ dnorm(0, tau.eps.site)\n      #identifiable site random effect (monitor this)\n      eps.site.star[t,s] &lt;- eps.site[t,s] - ave.eps.site[s]\n    }\n    #mean site level random effects within each species\n    ave.eps.site[s] &lt;- mean(eps.site[,s])\n  }\n  \n  #YEARS W/IN SPECIES RANDOM EFFECTS\n  #sites nested within species (sites sum to zero w/in each species)\n  for(s in 1:n.species){\n    for(y in 1:n.years){\n      #non-identifiable random effect\n      eps.year[y,s] ~ dnorm(0, tau.eps.year)\n      #identifiable year random effect (monitor this)\n      eps.year.star[y,s] &lt;- eps.year[y,s] - ave.eps.year[s]\n    }\n    #mean year level random effects within each species\n    ave.eps.year[s] &lt;- mean(eps.year[,s])\n  }\n  \n  #COMMUNITY HYPER PRIORS\n  #initial occupancy\n  #Detection intercept\n  mu.a0 ~ dnorm(0, 0.001)\n  tau.a0 &lt;- pow(sig.a0, -2)\n  sig.a0 ~ dunif(0, 50)\n  \n  #species-level abundance\n  mu.b0species ~ dnorm(0, 0.001)\n  tau.b0species &lt;- pow(sig.b0species, -2)\n  sig.b0species ~ dunif(0,50)\n  \n  #site and year variances\n  sig.eps.site ~ dunif(0, 10)\n  tau.eps.site &lt;- pow(sig.eps.site, -2)\n  sig.eps.year ~ dunif(0, 10)\n  tau.eps.year &lt;- pow(sig.eps.year, -2)\n  \n  #detection covariate effect priors\n  a1 ~ dnorm(0, 0.001)\n  #a2 ~ dnorm(0, 0.001)\n  \n  #IN CASE OF missing data \n  #If detection covariate data are missing, this will\n  #impute based on mean and variance of that variable\n  for(t in 1:n.transects){\n    for(y in n.start[t]:n.end[t]){\n      for(r in 1:n.rep[t,y]){\n        \n        survey.covariate[t,y,r] ~ dnorm(mu.surveycov, tau.surveycov)\n      }\n    }\n  }\n  \n  #PRIORS FOR IMPUTING MISSING DATA\n  #Priors for mean and tau of missing covariates in the model\n  mu.surveycov ~ dunif(-10, 10)\n  sig.surveycov ~ dunif(0, 20)\n  tau.surveycov &lt;- pow(sig.surveycov, -2)\n\n  #END MODEL\n}"
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html#the-model-in-action",
    "href": "01_accounting-for-imperfect-detection.html#the-model-in-action",
    "title": "1  Accounting for imperfect detection",
    "section": "1.2 The model in action",
    "text": "1.2 The model in action\nThese models take a long time to run and we utilized cloud computing to run them on real datasets. For illustration purposes, we have simulated a dataset with a small number of species, years, and survey units to illustrate how to run the model in JAGS and R.\nOur simulated dataset includes abundance data for:\n\n10 species from\n3 transects that come from\n1 site in\n5 years that all received\n2 surveys within each year\n\nIn this dataset, detection probability depends on a survey covariate that is different for each survey replicate at each site in each year (e.g., could be differences in survey length or weather during the survey). You can find the simulated dataset in tidy form here(PATH TO DATAFRAME NEEDED).\nTo run the model in R and JAGS, we will need:\n\nThe model file\nThe data list\nA script to wrap JAGS in R\n\nYou can find all of these, along with the data simulation used in this tutorial, in the [FOLDER]\n\n1.2.1 Running the model\n\n1.2.1.1 The model file\nYou will need to provide a path to the model file (which is its own R script, written in JAGS/BUGS language, so it won’t actually run in R). You can find ours here(PATH TO MODEL FILE). You will see that we define the path to this model in our model running script below.\n\n\n1.2.1.2 The data list\nTo run the model, we will need to provide JAGS with a data list, which you can find herePATH.\n\ndata_list &lt;- readRDS(here(\"MSAM\",\n                          'data',\n                          'model_inputs',\n                          'MSAM_data_list.RDS'))\n\nstr(data_list)\n\nList of 11\n $ Site.ID         : num [1:3] 1 1 1\n $ Year.ID         : int [1:5] 1 2 3 4 5\n $ survey.covariate: num [1:3, 1:5, 1:2] -0.626 1.512 0.919 -0.836 -0.621 ...\n $ count           : num [1:5, 1:3, 1:5, 1:2] 23 0 1 0 14 24 1 1 1 31 ...\n $ n.species       : num 5\n $ n.transects     : num 3\n $ n.sites         : num 1\n $ n.years         : num 5\n $ n.start         : num [1:3] 1 1 1\n $ n.end           : num [1:3] 5 5 5\n $ n.rep           : num [1:3, 1:5] 2 2 2 2 2 2 2 2 2 2 ...\n\n\nAs you can see, this data list includes indexing numbers, vectors, matrices, and arrays to pass to JAGS.\n\n\n1.2.1.3 The script to run the model\nWe’ll run the model using the jagsUI wrapper package. You can find this script herePATH, and the general code to run a JAGS model is provided here:\n\n# Load packages -----------------------------------------------------------\n\n\npackage.list &lt;- c(\"tidyverse\", 'here', #general packages\n                  'jagsUI', #jags wrapper\n                  'coda', #gelman.diag() function\n                  'mcmcplots') #trace plot function\n\n## Installing them if they aren't already on the computer\nnew.packages &lt;- package.list[!(package.list %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\n## And loading them\nfor(i in package.list){library(i, character.only = T)}\n\n# Load data -----------------------------------------------------------\n\ndata_list &lt;- readRDS(here(\"MSAM\",\n                          'data',\n                          'model_inputs',\n                          'MSAM_data_list.RDS'))\n\n# Define model path -----------------------------------------------------------\n\n#The model file is here:\nmodel_file &lt;- here(\"MSAM\",\n                   'code',\n                   'MSAM_model.R')\n\n# Specify parameters to save -----------------------------------------------------------\n\n#These are the parameters we will want to track \n#to assess convergence\nparameters &lt;- c('b0.star',\n                'a0',\n                'a1',\n                'eps.site.star',\n                'eps.year.star',\n                'mu.a0',\n                'sig.a0',\n                'mu.b0species',\n                'sig.b0species',\n                'sig.eps.site',\n                'sig.eps.year')\n\n# Set initial values for model -----------------------------------------------------------\n\n#this was also generated when we simulated data - it aids in \n#convergence when we have known values\ninits_list &lt;- readRDS(here(\"MSAM\",\n                           'data',\n                           \"model_inputs\",\n                           'MSAM_inits_list.RDS'))\n\n#IMPORTANT: You will need to set initial values for the number of \n#individuals (N), which will keep the model from running into errors\n#when a sampled number in the distribution exceeds the maximum\n#number observed at that site\n\n#We can also set initial values for various variables \n# with known values to get convergence faster, but these are not\n#necessary to get the model to run\ninits &lt;- list(list(a1 = inits_list$a1,\n                   mu.a0 = inits_list$mu.a0,\n                   mu.b0species = inits_list$mu.b0species,\n                   a0 = inits_list$a0,\n                   b0.species = inits_list$b0.species,\n                   eps.site = inits_list$eps.site,\n                   eps.year = inits_list$eps.year,\n                   N = inits_list$countmax),\n              list(a1 = inits_list$a1 + 0.05,\n                   mu.a0 = inits_list$mu.a0 + 0.05,\n                   mu.b0species = inits_list$mu.b0species + 0.05,\n                   a0 = inits_list$a0 + 0.05,\n                   b0.species = inits_list$b0.species + 0.05,\n                   eps.site = inits_list$eps.site + 0.05,\n                   eps.year = inits_list$eps.year + 0.05,\n                   N = inits_list$countmax),\n              list(a1 = inits_list$a1 - 0.05,\n                   mu.a0 = inits_list$mu.a0 - 0.05,\n                   mu.b0species = inits_list$mu.b0species - 0.05,\n                   a0 = inits_list$a0 - 0.05,\n                   b0.species = inits_list$b0.species - 0.05,\n                   eps.site = inits_list$eps.site - 0.05,\n                   eps.year = inits_list$eps.year - 0.05,\n                   N = inits_list$countmax))\n\n# Run the model -----------------------------------------------------------\n\n#run the model \nmodel &lt;- jagsUI::jags(data = data_list,\n                      inits = inits,\n                      parameters.to.save = parameters,\n                      model.file = model_file,\n                      parallel = TRUE,\n                      n.chains = 3,\n                      n.iter = 1335,\n                      DIC = TRUE)\n\n# Assess convergence -----------------------------------------------------------\n\n#assess convergence with Gelman statistic\ngelman.diag(model$samples, multivariate = F)\n#generate trace plots\nmcmcplot(model$samples)\n\nWe have run this just for enough iterations to assess convergence (it likely hasn’t converged) so that we can provide the model output for downstream tutorial steps. For your own datasets, you may need to keep running this model a few times for more iterations than we’ve shown above, resetting initial values based on new model runs to get this model to converge. For the datasets we evaluated in our manuscript, we set a convergence cutoff of &gt;95% of all nodes converging at Gelman diagnostic (\\(\\hat{R} \\leq 1.2\\)).\n\n\n\n1.2.2 Next: using N to compute indices of community stability\nNext up, we’ll use estimates of N for each species in each site in each year to calculate an index of community stability (beta diversity)!"
  }
]