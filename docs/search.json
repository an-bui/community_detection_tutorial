[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Community detection tutorial",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Community detection tutorial",
    "section": "Description",
    "text": "Description\nThis is a modeling tutorial for the supplement for Miller-ter Kuile et al. “Accounting for imperfect detection to reveal the importance of current and past environmental conditions for community stability”. in revision\nThe purpose of this tutorial is to provide a detailed description of the modeling approaches used in the paper along with examples of the models in action on both simulated and real datasets."
  },
  {
    "objectID": "index.html#case-studies",
    "href": "index.html#case-studies",
    "title": "Community detection tutorial",
    "section": "Case studies",
    "text": "Case studies\n[describe four datasets here]",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html",
    "href": "01_accounting-for-imperfect-detection.html",
    "title": "1  Accounting for imperfect detection",
    "section": "",
    "text": "Accounting for imperfect detection using Bayesian multi-species model (for either count or detection/non-detection)\n[look in supporting info for more]"
  },
  {
    "objectID": "02_computing-indices.html",
    "href": "02_computing-indices.html",
    "title": "2  Computing indices of community stability",
    "section": "",
    "text": "Measured community change (“stability”) through time\nchange in species presence/absence\nor change in BC dissimilarity\ncalculated posterior means and SD values for each change metric for each site and year\nused posterior means and standard deviation values in part 3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Computing indices of community stability</span>"
    ]
  },
  {
    "objectID": "03_community-stability-environment.html",
    "href": "03_community-stability-environment.html",
    "title": "3  Evaluating community stability in relation to environmental variables",
    "section": "",
    "text": "compiled abiotic and biotic variables that could influence community change\nDetermine whether responses to abiotic and biotic factors are instantaneous or lagged using Bayesian regression with stochastic antecedent modeling\nmodel structure",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Evaluating community stability in relation to environmental variables</span>"
    ]
  },
  {
    "objectID": "04_imperfect-detection.html",
    "href": "04_imperfect-detection.html",
    "title": "4  How imperfect detection shapes community change estimates across datasets",
    "section": "",
    "text": "assessed how accounting for imperfect detection influenced estimates of community change by comparing observed and modeled estimates of dissimilarity\nfirst creating observed dataset based on multiple sampling events per year\nthen created an observed dataset based on one sampling event per year\nexamined differences between observed datasets by using Bayesian hierarchical regression with change as response and data derivation crossed with dataset as predictor\npost-hoc pairwise tests to determine direction and magnitude of differences",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>How imperfect detection shapes community change estimates across datasets</span>"
    ]
  },
  {
    "objectID": "index.html#tools-youll-need",
    "href": "index.html#tools-youll-need",
    "title": "Community detection tutorial",
    "section": "Tools you’ll need",
    "text": "Tools you’ll need\nAll models are Bayesian models run in R and JAGS. You will need these programs to run these models.\nDownload R\n(We also recommend RStudio)\nDownload JAGS"
  },
  {
    "objectID": "index.html#outline",
    "href": "index.html#outline",
    "title": "Community detection tutorial",
    "section": "Outline",
    "text": "Outline\nIn the following pages, we will walk you through the model formulation as well as model code demonstrating the modeling framework."
  },
  {
    "objectID": "index.html#model-description",
    "href": "index.html#model-description",
    "title": "Community detection tutorial",
    "section": "Model description",
    "text": "Model description\nWe employed a two-step modeling process (Figure 1).\n ### A) Multi-species model accounting for imperfect detection\nThis model links observed abundance or presence-absence of species in a community to detection probabilities to generate a latent “true” abundance or occupancy for each species in each site in each year. We used this model to then generate metrics of community change (beta diversity). We built these models based on previous model developments for accounting for imperfect detection in community datasets (Dorazio et al. 2006).\n\nB) Regression model with environmental covariates\nThis model incorporates mean and variance of community change metrics from the model in A) into a regression examining the effects of environmental covariates on community change. This model employs a stochastic antecedent modeling (SAM) framework (Ogle et al. 2015) to allow environmental covariates to have immediate and lagged responses."
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html#model-formulation",
    "href": "01_accounting-for-imperfect-detection.html#model-formulation",
    "title": "1  Accounting for imperfect detection",
    "section": "1.1 Model Formulation",
    "text": "1.1 Model Formulation\nTraditional multi-species abundance (MSAM) and occupancy (MSOM) models are built on several data requirements and assumptions:\n\nSites are visited more than once within a year, so that repeat visits can be used to estimate detection probabilities.\nThere is “closure” within a year at a site, which means species are neither gained or lost from a site within that year.\n\nThese models have two components, including a) a biological process linking latent “true” abundance or occupancy to an expected value or probability, which could depend on covariates and b) an observation process linking observed data to detection probability and “true” abundance or occupancy.\n\n1.1.1 Data distribution\nIn all following mathematical descriptions and models, subscripts are as follows:\n\ns : species\nt : survey unit (e.g., transect, quadrat)\ny : year\nr : survey replicate\n\nFor abundance models, observed data, \\(y_{s,t,y,r}\\), is dependent on detection probability, \\(p_{s,t,y,r}\\), and “true” latent abundance, \\(N_{s,t,y}\\):\n\\(y_{s,t,y,r} \\sim Binomial(p_{s,t,y,r}, N_{s,t,y})\\)\nFor occupancy models, observed data, \\(y_{s,t,y,r}\\), is dependent on detection probability, \\(p_{s,t,y,r}\\), and “true” latent occupancy, \\(z_{s,t,y}\\) (\\(z_{s,t,y}\\) = 1: presence; \\(z_{s,t,y}\\) = 0: absence):\n\\(y_{s,t,y,r} \\sim Bernoulli(p_{s,t,y,r}* z_{s,t,y})\\)\n\n\n1.1.2 Biological process\nFor abundance models, latent abundance, \\(N_{s,t,y}\\), is dependent on a rate parameter \\(\\lambda_{s,t,y}\\):\n\\(N_{s,t,y} \\sim Poisson(\\lambda_{s,t,y})\\)\nWhich, in our models, is dependent on a regression that includes a species-specific intercept and random effects of site within species and year within species which are made identifiable based on the post-sweeping method described in Ogle and Barber (2020):\n\\(log(\\lambda_{s,t,y}) = \\beta_{0s} + \\epsilon_{s,t} + \\gamma_{s,y}\\)\nSimilarly, for occupancy models, \\(z_{s,t,y}\\) is dependent on occupancy probability, \\(\\psi_{s,t,y}\\):\n\\(z_{s,t,y} \\sim Bernoulli(psi_{s,t,y})\\)\nWhich is dependent on a similar regression:\n\\(logit(\\psi_{s,t,y}) = \\beta_{0s} + \\epsilon_{s,t} + \\gamma_{s,y}\\)\nAll species-level intercept values receive priors centered around community-level hyperparameters:\n\\(\\beta_{0s} \\sim Normal(\\mu_\\beta, \\sigma_\\beta)\\)\nWith vague or relatively uninformative priors:\n\\(\\mu_\\beta \\sim Normal(0, 1000)\\)\n\\(\\sigma_\\beta \\sim Uniform(0, 50)\\)\n\n\n1.1.3 Observation process\nFor both abundance and occupancy models, the observation process estimates detection probabilities, \\(p_{s,t,y,r}\\), which can be estimated based on a regression:\n\\(logit(p_{s,t,y,r}) = \\alpha_{0s} + \\sum_{j=1}^{J}\\alpha_jX_{j,s,t,y,r}\\)\nWhere \\(\\alpha_{0s}\\) is a species-level intercept and the coefficients \\(\\alpha_1\\), \\(\\alpha_2\\)… \\(\\alpha_J\\) denote the effect of each detection covariate \\(X_{j,s,t,y,r}\\) for j = 1, 2, … J. Each detection covariate, \\(X_{j,s,t,y,r}\\), can depend on any combination of species, site, year, and replicate (e.g., species traits would be an \\(X_s\\) whereas conditions during a survey might be a \\(X_{t,y,r}\\)).\nAgain, all species-level intercept values receive priors centered around community-level hyperparameters:\n\\(\\alpha_{0s} \\sim Normal(\\mu_\\alpha, \\sigma_\\alpha)\\)\nWith vague or relatively uninformative priors:\n\\(\\mu_\\alpha \\sim Normal(0, 1000)\\)\n\\(\\sigma_\\alpha \\sim Uniform(0, 50)\\)\nAll continous covariate effects got relatively uninformative priors\n\\(\\alpha_j \\sim Normal(0, 1000)\\)\nAnd categorical covariate effects were cell-referenced with the baseline level being that with the most observations (baseline level gets a prior value = 0, all others get uninformative normal priors similar to \\(alpha_j\\), above).\n\n\n1.1.4 The model translated to JAGS code\nBelow is example JAGS code for the model specified above:\n\nmodel{\n  \n  #Example MSAM model for tutorial with simulated data\n  \n  \n  for(s in 1:n.species){ #species\n    for(t in 1:n.transects){ #transects\n      for(y in n.start[t]:n.end[t]){ #years\n        #setting these start and end years to depend on transect\n        #allows them to vary by transect\n        \n        #BIOLOGICAL MODEL \n        \n        #expected number of individuals of species s\n        #in site t in time y is dependent on \n        #a rate parameter, lambda, for a poisson distribution\n        N[s,t,y] ~ dpois(lambda[s,t,y])\n        \n        #this rate parameter is dependent on a regression\n        #with a species intercept,\n        #and species within site, and species within year \n        #random effects (post-sweeping code is below for this )\n        log(lambda[s,t,y]) &lt;- b0.species[s] + \n          eps.site[Site.ID[t], s] +\n          eps.year[Year.ID[y], s]\n        \n        for(r in 1:n.rep[t,y]){ #for the number of surveys on each transect\n          #in each year\n          \n          # OBSERVATION MODEL\n          \n          #detection probability for species s in site t in\n          #year y in replicate r\n          logit(p[s,t,y,r]) &lt;- a0[s] + #species-level intercept\n            #a covariate that is related to the survey \n            #(e.g., weather, survey length)\n            #dependent on site, year, and replicate, but not species\n            a1*survey.covariate[t,y,r] #+\n          #could also add species covariates \n          #(e.g., body size, color, call frequency)\n            #a2*species.covariate[s]\n          \n          #abundance is binomial based on detection probability\n          #and total true abundance at the site\n          y[s,t,y,r] ~ dbin(p[s,t,y,r], N[s,t,y])\n          \n          #create replicate data based on model estimation to\n          #look at goodness-of-fit (regress y.rep ~ y)\n          y.rep[s,t,y,r] ~ dbin(p[s,t,y,r], N[s,t,y])\n          \n        }\n      }\n    }\n    \n    #SPECIES-LEVEL PRIORS:\n    #Detection intercept and slopes for each species\n    #are centered on community-level hyperpriors\n    a0[s] ~ dnorm(mu.a0,tau.a0)\n    \n    #\"baseline\" detection at vis = 0 and size = 0 \n    #on standardized scale\n    p0[s] &lt;- ilogit(a0[s])\n    \n    #species-level intercept - \n    #currently non-identifiable:\n    b0.species[s] ~ dnorm(mu.b0species, tau.b0species)\n    \n    #compute the identifiable species-level intercept:\n    #TRACK THIS ONE for convergence\n    b0.star[s] &lt;- b0.species[s] + ave.eps.site[s] + ave.eps.year[s]\n    \n  }\n  \n  #SITE W/IN SPECIES RANDOM EFFECTS\n  #sites nested within species (sites sum to zero w/in each species)\n  for(s in 1:n.species){\n    for(t in 1:n.sites){\n      #non-identifiable random effect\n      eps.site[t,s] ~ dnorm(0, tau.eps.site)\n      #identifiable site random effect (monitor this)\n      eps.site.star[t,s] &lt;- eps.site[t,s] - ave.eps.site[s]\n    }\n    #mean site level random effects within each species\n    ave.eps.site[s] &lt;- mean(eps.site[,s])\n  }\n  \n  #YEARS W/IN SPECIES RANDOM EFFECTS\n  #sites nested within species (sites sum to zero w/in each species)\n  for(s in 1:n.species){\n    for(y in 1:n.years){\n      #non-identifiable random effect\n      eps.year[y,s] ~ dnorm(0, tau.eps.year)\n      #identifiable year random effect (monitor this)\n      eps.year.star[y,s] &lt;- eps.year[y,s] - ave.eps.year[s]\n    }\n    #mean year level random effects within each species\n    ave.eps.year[s] &lt;- mean(eps.year[,s])\n  }\n  \n  #COMMUNITY HYPER PRIORS\n  #initial occupancy\n  #Detection intercept\n  mu.a0 ~ dnorm(0, 0.001)\n  tau.a0 &lt;- pow(sig.a0, -2)\n  sig.a0 ~ dunif(0, 50)\n  \n  #species-level abundance\n  mu.b0species ~ dnorm(0, 0.001)\n  tau.b0species &lt;- pow(sig.b0species, -2)\n  sig.b0species ~ dunif(0,50)\n  \n  #site and year variances\n  sig.eps.site ~ dunif(0, 10)\n  tau.eps.site &lt;- pow(sig.eps.site, -2)\n  sig.eps.year ~ dunif(0, 10)\n  tau.eps.year &lt;- pow(sig.eps.year, -2)\n  \n  #detection covariate effect priors\n  a1 ~ dnorm(0, 0.001)\n  #a2 ~ dnorm(0, 0.001)\n  \n  #IN CASE OF missing data \n  #If detection covariate data are missing, this will\n  #impute based on mean and variance of that variable\n  for(t in 1:n.transects){\n    for(y in n.start[t]:n.end[t]){\n      for(r in 1:n.rep[t,y]){\n        \n        survey.covariate[t,y,r] ~ dnorm(mu.surveycov, tau.surveycov)\n      }\n    }\n  }\n  \n  #PRIORS FOR IMPUTING MISSING DATA\n  #Priors for mean and tau of missing covariates in the model\n  mu.surveycov ~ dunif(-10, 10)\n  sig.surveycov ~ dunif(0, 20)\n  tau.surveycov &lt;- pow(sig.surveycov, -2)\n\n  #END MODEL\n}"
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html#the-model-in-action",
    "href": "01_accounting-for-imperfect-detection.html#the-model-in-action",
    "title": "1  Accounting for imperfect detection",
    "section": "1.2 The model in action",
    "text": "1.2 The model in action\nThese models take a long time to run and we utilized cloud computing to run them on real datasets. For illustration purposes, we have simulated a dataset with a small number of species, years, and survey units to illustrate how to run the model in JAGS and R.\nOur simulated dataset includes abundance data for:\n\n10 species from\n3 transects that come from\n1 site in\n5 years that all received\n2 surveys within each year\n\nIn this dataset, detection probability depends on a survey covariate that is different for each survey replicate at each site in each year (e.g., could be differences in survey length or weather during the survey). You can find the simulated dataset in tidy form here(PATH TO DATAFRAME NEEDED).\nTo run the model in R and JAGS, we will need:\n\nThe model file\nThe data list\nA script to wrap JAGS in R\n\nYou can find all of these, along with the data simulation used in this tutorial, in the [FOLDER]\n\n1.2.1 Running the model\n\n1.2.1.1 The model file\nYou will need to provide a path to the model file (which is its own R script, written in JAGS/BUGS language, so it won’t actually run in R). You can find ours here(PATH TO MODEL FILE). You will see that we define the path to this model in our model running script below.\n\n\n1.2.1.2 The data list\nTo run the model, we will need to provide JAGS with a data list, which you can find herePATH.\n\ndata_list &lt;- readRDS(here(\"MSAM\",\n                          'data',\n                          'model_inputs',\n                          'MSAM_data_list.RDS'))\n\nstr(data_list)\n\nList of 11\n $ Site.ID         : num [1:3] 1 1 1\n $ Year.ID         : int [1:5] 1 2 3 4 5\n $ survey.covariate: num [1:3, 1:5, 1:2] -0.626 1.512 0.919 -0.836 -0.621 ...\n $ count           : num [1:5, 1:3, 1:5, 1:2] 23 0 1 0 14 24 1 1 1 31 ...\n $ n.species       : num 5\n $ n.transects     : num 3\n $ n.sites         : num 1\n $ n.years         : num 5\n $ n.start         : num [1:3] 1 1 1\n $ n.end           : num [1:3] 5 5 5\n $ n.rep           : num [1:3, 1:5] 2 2 2 2 2 2 2 2 2 2 ...\n\n\nAs you can see, this data list includes indexing numbers, vectors, matrices, and arrays to pass to JAGS.\n\n\n1.2.1.3 The script to run the model\nWe’ll run the model using the jagsUI wrapper package. You can find this script herePATH, and the general code to run a JAGS model is provided here:\n\n# Load packages -----------------------------------------------------------\n\n\npackage.list &lt;- c(\"tidyverse\", 'here', #general packages\n                  'jagsUI', #jags wrapper\n                  'coda', #gelman.diag() function\n                  'mcmcplots') #trace plot function\n\n## Installing them if they aren't already on the computer\nnew.packages &lt;- package.list[!(package.list %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\n## And loading them\nfor(i in package.list){library(i, character.only = T)}\n\n# Load data -----------------------------------------------------------\n\ndata_list &lt;- readRDS(here(\"MSAM\",\n                          'data',\n                          'model_inputs',\n                          'MSAM_data_list.RDS'))\n\n# Define model path -----------------------------------------------------------\n\n#The model file is here:\nmodel_file &lt;- here(\"MSAM\",\n                   'code',\n                   'MSAM_model.R')\n\n# Specify parameters to save -----------------------------------------------------------\n\n#These are the parameters we will want to track \n#to assess convergence\nparameters &lt;- c('b0.star',\n                'a0',\n                'a1',\n                'eps.site.star',\n                'eps.year.star',\n                'mu.a0',\n                'sig.a0',\n                'mu.b0species',\n                'sig.b0species',\n                'sig.eps.site',\n                'sig.eps.year')\n\n# Set initial values for model -----------------------------------------------------------\n\n#this was also generated when we simulated data - it aids in \n#convergence when we have known values\ninits_list &lt;- readRDS(here(\"MSAM\",\n                           'data',\n                           \"model_inputs\",\n                           'MSAM_inits_list.RDS'))\n\n#IMPORTANT: You will need to set initial values for the number of \n#individuals (N), which will keep the model from running into errors\n#when a sampled number in the distribution exceeds the maximum\n#number observed at that site\n\n#We can also set initial values for various variables \n# with known values to get convergence faster, but these are not\n#necessary to get the model to run\ninits &lt;- list(list(a1 = inits_list$a1,\n                   mu.a0 = inits_list$mu.a0,\n                   mu.b0species = inits_list$mu.b0species,\n                   a0 = inits_list$a0,\n                   b0.species = inits_list$b0.species,\n                   eps.site = inits_list$eps.site,\n                   eps.year = inits_list$eps.year,\n                   N = inits_list$countmax),\n              list(a1 = inits_list$a1 + 0.05,\n                   mu.a0 = inits_list$mu.a0 + 0.05,\n                   mu.b0species = inits_list$mu.b0species + 0.05,\n                   a0 = inits_list$a0 + 0.05,\n                   b0.species = inits_list$b0.species + 0.05,\n                   eps.site = inits_list$eps.site + 0.05,\n                   eps.year = inits_list$eps.year + 0.05,\n                   N = inits_list$countmax),\n              list(a1 = inits_list$a1 - 0.05,\n                   mu.a0 = inits_list$mu.a0 - 0.05,\n                   mu.b0species = inits_list$mu.b0species - 0.05,\n                   a0 = inits_list$a0 - 0.05,\n                   b0.species = inits_list$b0.species - 0.05,\n                   eps.site = inits_list$eps.site - 0.05,\n                   eps.year = inits_list$eps.year - 0.05,\n                   N = inits_list$countmax))\n\n# Run the model -----------------------------------------------------------\n\n#run the model \nmodel &lt;- jagsUI::jags(data = data_list,\n                      inits = inits,\n                      parameters.to.save = parameters,\n                      model.file = model_file,\n                      parallel = TRUE,\n                      n.chains = 3,\n                      n.iter = 1335,\n                      DIC = TRUE)\n\n# Assess convergence -----------------------------------------------------------\n\n#assess convergence with Gelman statistic\ngelman.diag(model$samples, multivariate = F)\n#generate trace plots\nmcmcplot(model$samples)\n\nWe have run this just for enough iterations to assess convergence (it likely hasn’t converged) so that we can provide the model output for downstream tutorial steps. For your own datasets, you may need to keep running this model a few times for more iterations than we’ve shown above, resetting initial values based on new model runs to get this model to converge. For the datasets we evaluated in our manuscript, we set a convergence cutoff of &gt;95% of all nodes converging at Gelman diagnostic (\\(\\hat{R} \\leq 1.2\\)).\n\n\n\n1.2.2 Next: using N to compute indices of community stability\nNext up, we’ll use estimates of N for each species in each site in each year to calculate an index of community stability (beta diversity)!"
  },
  {
    "objectID": "02_computing-indices.html#computing-indices-of-community-stability",
    "href": "02_computing-indices.html#computing-indices-of-community-stability",
    "title": "2  Computing indices of community stability",
    "section": "2.1 Computing indices of community stability",
    "text": "2.1 Computing indices of community stability\n\n2.1.1 Bray-Curtis Dissimilarity\nBray-Curtis dissimilarlity describes changes in overall community abundance across time or space. This index is calculated by breaking the two communities being compared into three parts:\n\nThe total number of shared individuals in communities 1 and 2 (A)\nThe total number of individuals in only community 1 (B)\nThe total number of individuals in only community 2 (C)\n\nThen, dissimilarlity is calcluated as:\n\\(BC = \\frac{(B + C)}{(2A + B + C)}\\)\n\n\n2.1.2 Species turnover\nSpecies turnover is similar to Bray-Curtis dissimilarity - we break the two communities into three different groups:\n\nThe species shared between community 1 and 2 (A)\nThe species only in community 1 (B)\nThe species only in community 2 (C)\n\nThen, turnover is:\n\\(turnover = \\frac{(B + C)}{(A + B + C)}\\)\n\n\n2.1.3 Interpretting both metrics\nIn both metrics, values closer to 1 indicate that the two communities are more different (a larger fraction of individuals or species are different between communities 1 and 2 than are shared). In our case, we are calculating these change metrics between a given survey unit in a dataset (“community”) between adjacent timepoints. For most datasets, this means we are comparing communities in time y to time y+1. However, for one dataset (PFNP plants), survey intervals were &gt; 1 year apart, so we compared communities between adjacent time points (e.g. 2007 and 2014, 2014 and 2021)."
  },
  {
    "objectID": "02_computing-indices.html#dissimilarity-metrics-in-jags-models",
    "href": "02_computing-indices.html#dissimilarity-metrics-in-jags-models",
    "title": "2  Computing indices of community stability",
    "section": "2.2 Dissimilarity metrics in JAGS models",
    "text": "2.2 Dissimilarity metrics in JAGS models\n\n2.2.1 Model code\nWe included these metrics as “derived quantities” in our MSAM models that we then pulled from models after they had converged. You can also derive these quantities in R, which we did for the PFNP plant dataset and code to do so can be found hereFIND PATH\nThese derived quantities come at the end of the model code that we highlighted in the previous step (“Accounting for imperfect detection”), but we do not provide the whole model here for brevity. To see the model with both components, you can look at our model file in the MSAM tutorial folder\n\nmodel{\n  \n  #...\n  #This is all the model code that we provided in the \n  # \"Accounting for Imperfect Detection\" tab, so we do not provide it here, \n  #for brevity.\n  \n  #DERIVED QUANTIIES\n  \n  #Bray-Curtis dissimilarity\n  for(t in 1:n.transects){\n    for(y in (n.start[t]+1):n.end[t]){\n      for(s in 1:n.species){\n        # num individuals in both time periods per species\n        a[s,t,y] &lt;- min(N[s,t,y-1], N[s,t,y])\n        # num individuals only in first time point\n        b[s,t,y] &lt;- N[s,t,y-1] - a[s,t,y]\n        # num individuals only in second time point\n        c[s,t,y] &lt;- N[s,t,y] - a[s,t,y]\n      }\n      #for all years 2 onward:\n      #total number of shared individuals across time periods\n      A[t,y] &lt;- sum(a[,t,y])\n      #total number of individuals in only first time period\n      B[t,y] &lt;- sum(b[,t,y])\n      #total number of individuals in only second time period\n      C[t,y] &lt;- sum(c[,t,y])\n      \n      #total bray-curtis (B+C)/(2A+B+C)\n      num[t,y] &lt;- B[t,y] + C[t,y]\n      denom1[t,y] &lt;- 2*A[t,y]+B[t,y]+C[t,y]\n      #if all values are zero - this just keeps the eqn. from\n      #dividing by zero\n      denom[t,y] &lt;- ifelse(denom1[t,y]==0,1, denom1[t,y])\n      \n      #Calculate Bray-Curtis dissimiarlity\n      bray[t,y] &lt;- num[t,y]/denom[t,y]\n      \n    }\n  }\n}\n\n\n\n2.2.2 Updating the model to get change metrics\nWe updated our model for a short number of iterations to get good estimates of mean and standard deviation values for our change metrics. We then exported the mean and standard deviations for these metrics as “data” to be provided in the next model (Evaluating community stability in relation to environmental variables)\n\n# Load packages -----------------------------------------------------------\n\npackage.list &lt;- c(\"tidyverse\", 'here', #general packages\n                  'jagsUI') #jags wrapper\n\n## Installing them if they aren't already on the computer\nnew.packages &lt;- package.list[!(package.list %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\n## And loading them\nfor(i in package.list){library(i, character.only = T)}\n\n# Load converged model -----------------------------------------------------------\n\nmodel &lt;- readRDS(here(\"MSAM\",\n                      'data',\n                      'model_outputs',\n                      'MSAM_model_output.RDS'))\n\n# Update model to track Bray-Curtis ------------------------------------------------\n\n#now the parameter we want is just bray, none of the others\nparams2 &lt;- c(\"bray\")\n\n#run this model so we have ~4000 samples to calculate mean and SD\nmodel2 &lt;- update(model,\n                 parameters.to.save = params2,\n                 n.iter = 1335,\n                 parallel = TRUE)\n\n# Extract summary stats of bray ------------------------------------------------\n\n#get a summary of this model and the parameters we saved (bray)\nsum &lt;- summary(model2$samples)\n\n#pull out mean and SD values from that summary\nstats &lt;- as.data.frame(sum$statistics) %&gt;%\n  rownames_to_column(var = 'parm') %&gt;%\n  filter(parm != \"deviance\") %&gt;%\n  #re-connect these values with their transect and year IDs\n  separate(parm, \n           into = c(\"transect\", \"year\"),\n           sep = \",\") %&gt;%\n  mutate(transect = str_sub(transect, 6, (nchar(transect))),\n         year = str_sub(year, 1, (nchar(year)-1))) %&gt;%\n  mutate(transect = as.numeric(transect),\n         year = as.numeric(year)) %&gt;%\n  #select only the variables of interest\n  dplyr::select(transect, year, Mean, SD)\n\nWe have saved this dataframe in the MSAM tutorial folderPATH HERE.\nNow we have a nice dataframe with Bray-Curtis dissimilarity calculated for each site along its time series. You will notice that the year value starts with year 2 and this is because this is the first year in which we have two community values to compare.\n\nstr(stats)\n\n'data.frame':   12 obs. of  4 variables:\n $ transect: num  1 2 3 1 2 3 1 2 3 1 ...\n $ year    : num  2 2 2 3 3 3 4 4 4 5 ...\n $ Mean    : num  0.664 0.638 0.616 0.486 0.505 ...\n $ SD      : num  0.0266 0.026 0.0252 0.0362 0.0372 ...\n\n\n\n\n2.2.3 Next: Evaluating community stability in relation to environmental variables\nNext we will take these change values and incorporate them into a regression with environmental covariates to examine how these covariates shape communities."
  }
]