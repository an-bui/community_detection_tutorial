[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "If you’re rare, do I care? A modeling tutorial",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "If you’re rare, do I care? A modeling tutorial",
    "section": "Description",
    "text": "Description\nThis is a modeling tutorial for the supplement for Miller-ter Kuile et al. “If you’re rare, should I care? How imperfect detection changes relationships between biodiversity and global change drivers”.\nThe purpose of this tutorial is to provide a detailed description of the modeling approaches used in the paper along with examples of the models in action on both simulated and real datasets."
  },
  {
    "objectID": "index.html#tools-youll-need",
    "href": "index.html#tools-youll-need",
    "title": "If you’re rare, do I care? A modeling tutorial",
    "section": "Tools you’ll need",
    "text": "Tools you’ll need\nAll models are Bayesian models run in R and JAGS. You will need these programs to run these models.\nDownload R\n(We also recommend RStudio)\nDownload JAGS\nOther options are available for running Bayesian models, including Stan and NIMBLE. There is less flexibility but great usability for users of any experience level for running multi-species occupancy models in the package spOccupancy. Given the incorporation of uncertainty in the regression models we developed, it would be challenging to run them in programs with built-in regression model functions, but they can be built in any Bayesian modeling language/program (JAGS, Stan, BUGS, NIMBLE)."
  },
  {
    "objectID": "index.html#model-description",
    "href": "index.html#model-description",
    "title": "If you’re rare, do I care? A modeling tutorial",
    "section": "Model description",
    "text": "Model description\nWe employed a two-step modeling process (Figure 1).\n\n\n\nFigure 1: Depiction of the two-step modeling process, including A) accounting for imperfect detection using a multi-species occupancy or abundance model and B) using derived quantitites of community change along with their uncertainty in a regression examining current and past environmental drivers of change.\n\n\n\nA) Multi-species model accounting for imperfect detection\nThis model links observed abundance or presence-absence of species in a community to detection probabilities to generate a latent “true” abundance or occupancy for each species in each site in each year. We used this model to then generate metrics of biodiversity. We built these models based on previous model developments for accounting for imperfect detection in community datasets (Dorazio et al. 2006).\n\n\nB) Regression model with environmental covariates\nThis model incorporates mean and variance of biodiversity metrics from the model in A) into a regression examining the effects of environmental covariates on biodiversity. This model employs a stochastic antecedent modeling (SAM) framework (Ogle et al. 2015) to allow environmental covariates to have immediate and lagged responses."
  },
  {
    "objectID": "index.html#outline",
    "href": "index.html#outline",
    "title": "If you’re rare, do I care? A modeling tutorial",
    "section": "Outline",
    "text": "Outline\nIn the following pages, we will walk you through the model formulation as well as model code demonstrating the modeling framework.\n\nAccounting for imperfect detection walks through accounting for imperfect detection in a multi-species model\nComputing indices of biodiversity illustrates how posterior samples for latent occupancy or abundance from the models for imperfect detection can be used to calculate multiple indices of biodiversity either inside Bayesian modeling software as derived quantities or through functions available in a variety of R packages\nEvaluating biodiversity in relation to environmental variables shows how to take these derived values of biodiversity and uncertainty around them and use them in a regression that allows covariates to have immediate and lagged effects on biodiversity metrics\n\n\n\n\n\nDorazio, Robert M., Andrew Royle, Bo Soderstrom, and Anders Glimskar. 2006. “Estimating Species Richness and Accumulation by Modeling Species Occurence and Detectability.” Ecology 87 (4): 842–54. https://doi.org/10.1890/0012-9658(2006)87[842:ESRAAB]2.0.CO;2.\n\n\nOgle, Kiona, Jarrett J. Barber, Greg A. Barron-Gafford, Lisa Patrick Bentley, Jessica M. Young, Travis E. Huxman, Michael E. Loik, and David T. Tissue. 2015. “Quantifying Ecological Memory in Plant and Ecosystem Processes.” Edited by Elsa Cleland. Ecology Letters 18 (3): 221–35. https://doi.org/10.1111/ele.12399."
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html#model-formulation",
    "href": "01_accounting-for-imperfect-detection.html#model-formulation",
    "title": "1  Accounting for imperfect detection",
    "section": "1.1 Model Formulation",
    "text": "1.1 Model Formulation\nTraditional multi-species abundance (MSAM) and occupancy (MSOM) models (Dorazio et al. 2006) are built on several data requirements and assumptions:\n\nSites are visited more than once within a year, so that repeat visits can be used to estimate detection probabilities.\nThere is “closure” within a year at a site, which means species are neither gained or lost from a site within that year.\n\nThese models have two components, including a) a biological process linking latent “true” abundance or occupancy to an expected value or probability, which could depend on covariates and b) an observation process linking observed data to detection probability and “true” abundance or occupancy.\n\n1.1.1 Data distribution\nIn all following mathematical descriptions and models, subscripts are as follows:\n\ns : species\nt : survey unit (e.g., transect, quadrat)\ny : year\nr : survey replicate\n\nFor abundance models, observed data, \\(y_{s,t,y,r}\\), is dependent on detection probability, \\(p_{s,t,y,r}\\), and “true” latent abundance, \\(N_{s,t,y}\\):\n\\(y_{s,t,y,r} \\sim Binomial(p_{s,t,y,r}, N_{s,t,y})\\)\nFor occupancy models, observed data, \\(y_{s,t,y,r}\\), is dependent on detection probability, \\(p_{s,t,y,r}\\), and “true” latent occupancy, \\(z_{s,t,y}\\) (\\(z_{s,t,y}\\) = 1: presence; \\(z_{s,t,y}\\) = 0: absence):\n\\(y_{s,t,y,r} \\sim Bernoulli(p_{s,t,y,r}* z_{s,t,y})\\)\n\n\n1.1.2 Biological process\nFor abundance models, latent abundance, \\(N_{s,t,y}\\), is dependent on a rate parameter \\(\\lambda_{s,t,y}\\):\n\\(N_{s,t,y} \\sim Poisson(\\lambda_{s,t,y})\\)\nWhich, in our models, is dependent on a regression that includes a species-specific intercept and random effects of site within species and year within species which are made identifiable based on the post-sweeping method described in (Ogle and Barber 2020):\n\\(log(\\lambda_{s,t,y}) = \\beta_{0s} + \\epsilon_{s,t} + \\gamma_{s,y}\\)\nSimilarly, for occupancy models, \\(z_{s,t,y}\\) is dependent on occupancy probability, \\(\\psi_{s,t,y}\\):\n\\(z_{s,t,y} \\sim Bernoulli(psi_{s,t,y})\\)\nWhich is dependent on a similar regression:\n\\(logit(\\psi_{s,t,y}) = \\beta_{0s} + \\epsilon_{s,t} + \\gamma_{s,y}\\)\nAll species-level intercept values receive priors centered around community-level hyperparameters:\n\\(\\beta_{0s} \\sim Normal(\\mu_\\beta, \\sigma_\\beta)\\)\nWith vague or relatively uninformative priors:\n\\(\\mu_\\beta \\sim Normal(0, 1000)\\)\n\\(\\sigma_\\beta \\sim Uniform(0, 50)\\)\n\n\n1.1.3 Observation process\nFor both abundance and occupancy models, the observation process estimates detection probabilities, \\(p_{s,t,y,r}\\), which can be estimated based on a regression:\n\\(logit(p_{s,t,y,r}) = \\alpha_{0s} + \\sum_{j=1}^{J}\\alpha_jX_{j,s,t,y,r}\\)\nWhere \\(\\alpha_{0s}\\) is a species-level intercept and the coefficients \\(\\alpha_1\\), \\(\\alpha_2\\)… \\(\\alpha_J\\) denote the effect of each detection covariate \\(X_{j,s,t,y,r}\\) for j = 1, 2, … J. Each detection covariate, \\(X_{j,s,t,y,r}\\), can depend on any combination of species, site, year, and replicate (e.g., species traits would be an \\(X_s\\) whereas conditions during a survey might be a \\(X_{t,y,r}\\)).\nAgain, all species-level intercept values receive priors centered around community-level hyperparameters:\n\\(\\alpha_{0s} \\sim Normal(\\mu_\\alpha, \\sigma_\\alpha)\\)\nWith vague or relatively uninformative priors:\n\\(\\mu_\\alpha \\sim Normal(0, 1000)\\)\n\\(\\sigma_\\alpha \\sim Uniform(0, 50)\\)\nAll continous covariate effects got relatively uninformative priors\n\\(\\alpha_j \\sim Normal(0, 1000)\\)\nAnd categorical covariate effects were cell-referenced with the baseline level being that with the most observations (baseline level gets a prior value = 0, all others get uninformative normal priors similar to \\(alpha_j\\), above).\n\n\n1.1.4 The model translated to JAGS code\nBelow is example JAGS code for the model specified above:\n\nmodel{\n  \n  #Example MSAM model for tutorial with simulated data\n  \n  \n  for(s in 1:n.species){ #species\n    for(t in 1:n.transects){ #transects\n      for(y in n.start[t]:n.end[t]){ #years\n        #setting these start and end years to depend on transect\n        #allows them to vary by transect\n        \n        #BIOLOGICAL MODEL \n        \n        #expected number of individuals of species s\n        #in site t in time y is dependent on \n        #a rate parameter, lambda, for a poisson distribution\n        N[s,t,y] ~ dpois(lambda[s,t,y])\n        \n        #this rate parameter is dependent on a regression\n        #with a species intercept,\n        #and species within site, and species within year \n        #random effects (post-sweeping code is below for this )\n        log(lambda[s,t,y]) &lt;- b0.species[s] + \n          eps.site[Site.ID[t], s] +\n          eps.year[Year.ID[y], s]\n        \n        for(r in 1:n.rep[t,y]){ #for the number of surveys on each transect\n          #in each year\n          \n          # OBSERVATION MODEL\n          \n          #detection probability for species s in site t in\n          #year y in replicate r\n          logit(p[s,t,y,r]) &lt;- a0[s] + #species-level intercept\n            #a covariate that is related to the survey \n            #(e.g., weather, survey length)\n            #dependent on site, year, and replicate, but not species\n            a1*survey.covariate[t,y,r] #+\n          #could also add species covariates \n          #(e.g., body size, color, call frequency)\n            #a2*species.covariate[s]\n          \n          #abundance is binomial based on detection probability\n          #and total true abundance at the site\n          y[s,t,y,r] ~ dbin(p[s,t,y,r], N[s,t,y])\n          \n          #create replicate data based on model estimation to\n          #look at goodness-of-fit (regress y.rep ~ y)\n          y.rep[s,t,y,r] ~ dbin(p[s,t,y,r], N[s,t,y])\n          \n        }\n      }\n    }\n    \n    #SPECIES-LEVEL PRIORS:\n    #Detection intercept and slopes for each species\n    #are centered on community-level hyperpriors\n    a0[s] ~ dnorm(mu.a0,tau.a0)\n    \n    #\"baseline\" detection at vis = 0 and size = 0 \n    #on standardized scale\n    p0[s] &lt;- ilogit(a0[s])\n    \n    #species-level intercept - \n    #currently non-identifiable:\n    b0.species[s] ~ dnorm(mu.b0species, tau.b0species)\n    \n    #compute the identifiable species-level intercept:\n    #TRACK THIS ONE for convergence\n    b0.star[s] &lt;- b0.species[s] + ave.eps.site[s] + ave.eps.year[s]\n    \n  }\n  \n  #SITE W/IN SPECIES RANDOM EFFECTS\n  #sites nested within species (sites sum to zero w/in each species)\n  for(s in 1:n.species){\n    for(t in 1:n.sites){\n      #non-identifiable random effect\n      eps.site[t,s] ~ dnorm(0, tau.eps.site)\n      #identifiable site random effect (monitor this)\n      eps.site.star[t,s] &lt;- eps.site[t,s] - ave.eps.site[s]\n    }\n    #mean site level random effects within each species\n    ave.eps.site[s] &lt;- mean(eps.site[,s])\n  }\n  \n  #YEARS W/IN SPECIES RANDOM EFFECTS\n  #sites nested within species (sites sum to zero w/in each species)\n  for(s in 1:n.species){\n    for(y in 1:n.years){\n      #non-identifiable random effect\n      eps.year[y,s] ~ dnorm(0, tau.eps.year)\n      #identifiable year random effect (monitor this)\n      eps.year.star[y,s] &lt;- eps.year[y,s] - ave.eps.year[s]\n    }\n    #mean year level random effects within each species\n    ave.eps.year[s] &lt;- mean(eps.year[,s])\n  }\n  \n  #COMMUNITY HYPER PRIORS\n  #initial occupancy\n  #Detection intercept\n  mu.a0 ~ dnorm(0, 0.001)\n  tau.a0 &lt;- pow(sig.a0, -2)\n  sig.a0 ~ dunif(0, 50)\n  \n  #species-level abundance\n  mu.b0species ~ dnorm(0, 0.001)\n  tau.b0species &lt;- pow(sig.b0species, -2)\n  sig.b0species ~ dunif(0,50)\n  \n  #site and year variances\n  sig.eps.site ~ dunif(0, 10)\n  tau.eps.site &lt;- pow(sig.eps.site, -2)\n  sig.eps.year ~ dunif(0, 10)\n  tau.eps.year &lt;- pow(sig.eps.year, -2)\n  \n  #detection covariate effect priors\n  a1 ~ dnorm(0, 0.001)\n  #a2 ~ dnorm(0, 0.001)\n  \n  #IN CASE OF missing data \n  #If detection covariate data are missing, this will\n  #impute based on mean and variance of that variable\n  for(t in 1:n.transects){\n    for(y in n.start[t]:n.end[t]){\n      for(r in 1:n.rep[t,y]){\n        \n        survey.covariate[t,y,r] ~ dnorm(mu.surveycov, tau.surveycov)\n      }\n    }\n  }\n  \n  #PRIORS FOR IMPUTING MISSING DATA\n  #Priors for mean and tau of missing covariates in the model\n  mu.surveycov ~ dunif(-10, 10)\n  sig.surveycov ~ dunif(0, 20)\n  tau.surveycov &lt;- pow(sig.surveycov, -2)\n\n  #END MODEL\n}"
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html#the-model-in-action",
    "href": "01_accounting-for-imperfect-detection.html#the-model-in-action",
    "title": "1  Accounting for imperfect detection",
    "section": "1.2 The model in action",
    "text": "1.2 The model in action\nThese models take a long time to run and we utilized cloud computing to run them on real datasets. For illustration purposes, we have simulated a dataset with a small number of species, years, and survey units to illustrate how to run the model in JAGS and R.\nOur simulated dataset includes abundance data for:\n\n10 species from\n3 transects that come from\n1 site in\n5 years that all received\n2 surveys within each year\n\nIn this dataset, detection probability depends on a survey covariate that is different for each survey replicate at each site in each year (e.g., could be differences in survey length or weather during the survey).\nTo run the model in R and JAGS, we will need:\n\nThe model file\nThe data list\nA script to wrap JAGS in R\n\nYou can find all of these, along with the data simulation and tidy version of the simulated data used in this tutorial, in the MSAM tutorial folder.\n\n1.2.1 Running the model\n\n1.2.1.1 The model file\nYou will need to provide a path to the model file (which is its own R script, written in JAGS/BUGS language, so it won’t actually run in R). You can find ours here. You will see that we define the path to this model in our model running script below.\n\n\n1.2.1.2 The data list\nTo run the model, we will need to provide JAGS with a data list, which you can find here. We have code on how to prepare the data list here.\n\ndata_list &lt;- readRDS(here('tutorials',\n                          \"01_imperfect_detect\",\n                          'data',\n                          'model_inputs',\n                          'MSAM_data_list.RDS'))\n\nstr(data_list)\n\nList of 11\n $ Site.ID         : num [1:3] 1 1 1\n $ Year.ID         : int [1:5] 1 2 3 4 5\n $ survey.covariate: num [1:3, 1:5, 1:2] -0.626 1.512 0.919 -0.836 -0.621 ...\n $ count           : num [1:5, 1:3, 1:5, 1:2] 23 0 1 0 14 24 1 1 1 31 ...\n $ n.species       : num 5\n $ n.transects     : num 3\n $ n.sites         : num 1\n $ n.years         : num 5\n $ n.start         : num [1:3] 1 1 1\n $ n.end           : num [1:3] 5 5 5\n $ n.rep           : num [1:3, 1:5] 2 2 2 2 2 2 2 2 2 2 ...\n\n\nAs you can see, this data list includes indexing numbers, vectors, matrices, and arrays to pass to JAGS.\n\n\n1.2.1.3 The script to run the model\nWe’ll run the model using the jagsUI wrapper package. You can find this script here, and the general code to run a JAGS model is provided here:\n\n# Load packages -----------------------------------------------------------\n\n\npackage.list &lt;- c(\"tidyverse\", 'here', #general packages\n                  'jagsUI', #jags wrapper\n                  'coda', #gelman.diag() function\n                  'mcmcplots') #trace plot function\n\n## Installing them if they aren't already on the computer\nnew.packages &lt;- package.list[!(package.list %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\n## And loading them\nfor(i in package.list){library(i, character.only = T)}\n\n# Load data -----------------------------------------------------------\n\ndata_list &lt;- readRDS(here('tutorials',\n                          \"01_imperfect_detect\",\n                          'data',\n                          'model_inputs',\n                          'MSAM_data_list.RDS'))\n\n# Define model path -----------------------------------------------------------\n\n#The model file is here:\nmodel_file &lt;- here('tutorials',\n                   \"01_imperfect_detect\",\n                   'code',\n                   'MSAM_model.R')\n\n# Specify parameters to save -----------------------------------------------------------\n\n#These are the parameters we will want to track \n#to assess convergence\nparameters &lt;- c('b0.star',\n                'a0',\n                'a1',\n                'eps.site.star',\n                'eps.year.star',\n                'mu.a0',\n                'sig.a0',\n                'mu.b0species',\n                'sig.b0species',\n                'sig.eps.site',\n                'sig.eps.year')\n\n# Set initial values for model -----------------------------------------------------------\n\n#this was also generated when we simulated data - it aids in \n#convergence when we have known values\ninits_list &lt;- readRDS(here('tutorials',\n                           \"01_imperfect_detect\",\n                           'data',\n                           \"model_inputs\",\n                           'MSAM_inits_list.RDS'))\n\n#IMPORTANT: You will need to set initial values for the number of \n#individuals (N), which will keep the model from running into errors\n#when a sampled number in the distribution exceeds the maximum\n#number observed at that site\n\n#We can also set initial values for various variables \n# with known values to get convergence faster, but these are not\n#necessary to get the model to run\ninits &lt;- list(list(a1 = inits_list$a1,\n                   mu.a0 = inits_list$mu.a0,\n                   mu.b0species = inits_list$mu.b0species,\n                   a0 = inits_list$a0,\n                   b0.species = inits_list$b0.species,\n                   eps.site = inits_list$eps.site,\n                   eps.year = inits_list$eps.year,\n                   N = inits_list$countmax),\n              list(a1 = inits_list$a1 + 0.05,\n                   mu.a0 = inits_list$mu.a0 + 0.05,\n                   mu.b0species = inits_list$mu.b0species + 0.05,\n                   a0 = inits_list$a0 + 0.05,\n                   b0.species = inits_list$b0.species + 0.05,\n                   eps.site = inits_list$eps.site + 0.05,\n                   eps.year = inits_list$eps.year + 0.05,\n                   N = inits_list$countmax),\n              list(a1 = inits_list$a1 - 0.05,\n                   mu.a0 = inits_list$mu.a0 - 0.05,\n                   mu.b0species = inits_list$mu.b0species - 0.05,\n                   a0 = inits_list$a0 - 0.05,\n                   b0.species = inits_list$b0.species - 0.05,\n                   eps.site = inits_list$eps.site - 0.05,\n                   eps.year = inits_list$eps.year - 0.05,\n                   N = inits_list$countmax))\n\n# Run the model -----------------------------------------------------------\n\n#run the model \nmodel &lt;- jagsUI::jags(data = data_list,\n                      inits = inits,\n                      parameters.to.save = parameters,\n                      model.file = model_file,\n                      parallel = TRUE,\n                      n.chains = 3,\n                      n.iter = 1335,\n                      DIC = TRUE)\n\n# Assess convergence -----------------------------------------------------------\n\n#assess convergence with Gelman statistic\ngelman.diag(model$samples, multivariate = F)\n#generate trace plots\nmcmcplot(model$samples)\n\nWe have run this just for enough iterations to assess convergence (it likely hasn’t converged) so that we can provide the model output for downstream tutorial steps. For your own datasets, you may need to keep running this model a few times for more iterations than we’ve shown above, resetting initial values based on new model runs to get this model to converge. For the datasets we evaluated in our manuscript, we set a convergence cutoff of &gt;95% of all nodes converging at Gelman diagnostic (\\(\\hat{R} \\leq 1.2\\)).\n\n\n\n1.2.2 Next: using N, \\(z\\), or \\(\\psi\\) to compute indices of biodiversity\nNext up, we’ll use estimates of N (or \\(z\\) or \\(\\psi\\) for an occupancy model) for each species in each site in each year to calculate indices of biodiversity!\n\n\n\n\nDorazio, Robert M., Andrew Royle, Bo Soderstrom, and Anders Glimskar. 2006. “Estimating Species Richness and Accumulation by Modeling Species Occurence and Detectability.” Ecology 87 (4): 842–54. https://doi.org/10.1890/0012-9658(2006)87[842:ESRAAB]2.0.CO;2.\n\n\nOgle, Kiona, and Jarrett J. Barber. 2020. “Ensuring Identifiability in Hierarchical Mixed Effects Bayesian Models.” Ecological Applications 30 (7): e02159. https://doi.org/10.1002/eap.2159."
  },
  {
    "objectID": "02_computing-indices.html#computing-indices-of-biodiversity",
    "href": "02_computing-indices.html#computing-indices-of-biodiversity",
    "title": "2  Computing indices of biodiversity",
    "section": "2.1 Computing indices of biodiversity",
    "text": "2.1 Computing indices of biodiversity\n\n2.1.1 Bray-Curtis Dissimilarity\nBray-Curtis dissimilarlity describes changes in overall community abundance across time or space. This index is calculated by breaking the two communities being compared into three parts:\n\nThe total number of shared individuals in communities 1 and 2 (A)\nThe total number of individuals in only community 1 (B)\nThe total number of individuals in only community 2 (C)\n\nThen, dissimilarlity is calcluated as:\n\\(BC = \\frac{(B + C)}{(2A + B + C)}\\)\n\n\n2.1.2 Species turnover\nSpecies turnover is similar to Bray-Curtis dissimilarity - we break the two communities into three different groups:\n\nThe species shared between community 1 and 2 (A)\nThe species only in community 1 (B)\nThe species only in community 2 (C)\n\nThen, turnover is:\n\\(turnover = \\frac{(B + C)}{(A + B + C)}\\)\nFor this study (plant dataset), we decomposed turnover into “gains” and “losses” by just including either \\(B\\) (losses) or \\(C\\) (gains) in the denominator.\n\n\n2.1.3 Interpretting both metrics\nIn both metrics, values closer to 1 indicate that the two communities are more different (a larger fraction of individuals or species are different between communities 1 and 2 than are shared). In our case, we are calculating these change metrics between a given survey unit in a dataset (“community”) between adjacent timepoints. For most datasets, this means we are comparing communities in time y to time y+1. However, for one dataset (PFNP plants), survey intervals were &gt; 1 year apart, so we compared communities between adjacent time points (e.g. 2007 and 2014, 2014 and 2021).\n\n\n2.1.4 Notation in our paper\nIn the paper, we define a general biodiversity metric as \\(d_{t,y}\\). And use the mean (\\(\\bar{d}_{t,y}\\)) and variance (\\(Var(\\bar{d}_{t,y})\\)) of this value as “data” in the environmental regression model."
  },
  {
    "objectID": "02_computing-indices.html#biodiversity-metrics-in-jags-models",
    "href": "02_computing-indices.html#biodiversity-metrics-in-jags-models",
    "title": "2  Computing indices of biodiversity",
    "section": "2.2 Biodiversity metrics in JAGS models",
    "text": "2.2 Biodiversity metrics in JAGS models\n\n2.2.1 Model code\nWe can include these metrics as “derived quantities” in our MSAM models that we can pull from models after they have converged. You can also derive these quantities in R, and we provide an example in the code in the tutorial folder.\nWhen incorporating derived quantities into JAGS code, these quantities come at the end of the model code that we highlighted in the previous step (“Accounting for imperfect detection”), but we do not provide the whole model here for brevity. To see the model with both components, you can look at our model file in the imperfect detection tutorial folder.\n\nmodel{\n  \n  #...\n  #This is all the model code that we provided in the \n  # \"Accounting for Imperfect Detection\" tab, so we do not provide it here, \n  #for brevity.\n  \n  #DERIVED QUANTIIES\n  \n  #Bray-Curtis dissimilarity\n  for(t in 1:n.transects){\n    for(y in (n.start[t]+1):n.end[t]){\n      for(s in 1:n.species){\n        # num individuals in both time periods per species\n        a[s,t,y] &lt;- min(N[s,t,y-1], N[s,t,y])\n        # num individuals only in first time point\n        b[s,t,y] &lt;- N[s,t,y-1] - a[s,t,y]\n        # num individuals only in second time point\n        c[s,t,y] &lt;- N[s,t,y] - a[s,t,y]\n      }\n      #for all years 2 onward:\n      #total number of shared individuals across time periods\n      A[t,y] &lt;- sum(a[,t,y])\n      #total number of individuals in only first time period\n      B[t,y] &lt;- sum(b[,t,y])\n      #total number of individuals in only second time period\n      C[t,y] &lt;- sum(c[,t,y])\n      \n      #total bray-curtis (B+C)/(2A+B+C)\n      num[t,y] &lt;- B[t,y] + C[t,y]\n      denom1[t,y] &lt;- 2*A[t,y]+B[t,y]+C[t,y]\n      #if all values are zero - this just keeps the eqn. from\n      #dividing by zero\n      denom[t,y] &lt;- ifelse(denom1[t,y]==0,1, denom1[t,y])\n      \n      #Calculate Bray-Curtis dissimiarlity\n      bray[t,y] &lt;- num[t,y]/denom[t,y]\n      \n    }\n  }\n}\n\n\n\n2.2.2 Updating the model to get biodiversity metrics\nWe updated our converged model for a short number of iterations to get good estimates of mean and standard deviation values for our biodiversity metrics. We then exported the mean and standard deviations for these metrics as “data” to be provided in the next model (Evaluating biodiversity in relation to environmental variables)\n\n# Load packages -----------------------------------------------------------\n\npackage.list &lt;- c(\"tidyverse\", 'here', #general packages\n                  'jagsUI') #jags wrapper\n\n## Installing them if they aren't already on the computer\nnew.packages &lt;- package.list[!(package.list %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\n## And loading them\nfor(i in package.list){library(i, character.only = T)}\n\n# Load converged model -----------------------------------------------------------\n\nmodel &lt;- readRDS(here('tutorials',\n                      \"01_imperfect_detect\",\n                      'data',\n                      'model_outputs',\n                      'MSAM_model_output.RDS'))\n\n# Update model to track Bray-Curtis ------------------------------------------------\n\n#now the parameter we want is just bray, none of the others\nparams2 &lt;- c(\"bray\")\n\n#run this model so we have ~4000 samples to calculate mean and SD\nmodel2 &lt;- update(model,\n                 parameters.to.save = params2,\n                 n.iter = 1335,\n                 parallel = TRUE)\n\n# Extract summary stats of bray ------------------------------------------------\n\n#get a summary of this model and the parameters we saved (bray)\nsum &lt;- summary(model2$samples)\n\n#pull out mean and SD values from that summary\nstats &lt;- as.data.frame(sum$statistics) %&gt;%\n  rownames_to_column(var = 'parm') %&gt;%\n  filter(parm != \"deviance\") %&gt;%\n  #re-connect these values with their transect and year IDs\n  separate(parm, \n           into = c(\"transect\", \"year\"),\n           sep = \",\") %&gt;%\n  mutate(transect = str_sub(transect, 6, (nchar(transect))),\n         year = str_sub(year, 1, (nchar(year)-1))) %&gt;%\n  mutate(transect = as.numeric(transect),\n         year = as.numeric(year)) %&gt;%\n  #select only the variables of interest\n  dplyr::select(transect, year, Mean, SD)\n\nWe have saved this dataframe in the imperfect detection tutorial folder.\nNow we have a nice dataframe with mean (\\(\\bar{d}_{t,y}\\)) and standard deviation (\\(\\hat{\\sigma}(\\bar{d}_{t,y})\\)) for the Bray-Curtis dissimilarity calculated for each site along its time series. You will notice that the year value starts with year 2 and this is because this is the first year in which we have two community values to compare. and variance\n\nstr(stats)\n\n'data.frame':   12 obs. of  4 variables:\n $ transect: num  1 2 3 1 2 3 1 2 3 1 ...\n $ year    : num  2 2 2 3 3 3 4 4 4 5 ...\n $ Mean    : num  0.664 0.638 0.616 0.486 0.505 ...\n $ SD      : num  0.0266 0.026 0.0252 0.0362 0.0372 ...\n\n\nWe can also look at how Bray-Curtis dissimilarity changes through time for each of our transects in our simulated datasets.\n\nlabels &lt;- c(\"Transect 1\", \"Transect 2\", \"Transect 3\")\nnames(labels) &lt;- c('1', '2', '3')\n\nggplot(stats) +\n  geom_ribbon(aes(x = year, ymin = Mean-SD, ymax = Mean+SD), alpha = 0.6) +\n  geom_line(aes(x = year, y = Mean)) +\n  facet_grid(~transect, labeller = labeller(transect = labels)) +\n  theme_bw() +\n  theme(strip.background = element_rect(fill = \"white\")) +\n  labs(x = \"Year\", y = \"Bray-Curtis dissimilarity \\n (Posterior mean and SD)\")\n\n\n\n\n\n\n2.2.3 Next: Evaluating biodiversity in relation to environmental variables\nNext we will take the mean and standard deviation of these biodiversity values and incorporate them into a regression with environmental covariates to examine how these covariates shape communities.\n\n\n\n\nGrenié, M, and H Gruson. 2025. Fundiversity: Easy Computation of Functional Diversity Indices. https://CRAN.R-project.org/package=fundiversity.\n\n\nHallett, Lauren M., Sydney K. Jones, A. Andrew M. MacDonald, Matthew B. Jones, Dan F. B. Flynn, Julie Ripplinger, Peter Slaughter, Corinna Gries, and Scott L. Collins. 2016. “Codyn: Anrpackage of Community Dynamics Metrics.” Edited by Timothée Poisot. Methods in Ecology and Evolution 7 (10): 1146–51. https://doi.org/10.1111/2041-210x.12569.\n\n\nMorris, E. Kathryn, Tancredi Caruso, François Buscot, Markus Fischer, Christine Hancock, Tanja S. Maier, Torsten Meiners, et al. 2014. “Choosing and Using Diversity Indices: Insights for Ecological Applications from the German Biodiversity Exploratories.” Ecology and Evolution 4 (18): 3514–24. https://doi.org/10.1002/ece3.1155.\n\n\nOksanen, Jari, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt, Pierre Legendre, Dan McGlinn, Peter R. Minchin, et al. 2020. Vegan: Community Ecology Package. https://CRAN.R-project.org/package=vegan."
  },
  {
    "objectID": "03_community-stability-environment.html#model-formulation",
    "href": "03_community-stability-environment.html#model-formulation",
    "title": "3  Evaluating biodiversity in relation to environmental variables",
    "section": "3.1 Model formulation",
    "text": "3.1 Model formulation\nLike many diversity metrics, our diversity metrics are functionally proportions, so the data have domain \\([0,1]\\). We can model proportions with a beta distribution, where the mean metric calculated in the previous step, \\(\\bar{d}_{t,y}\\), is beta distributed:\n\\(\\bar{d}_{t,y} \\sim Beta(\\alpha_{t,y}, \\beta_{t,y})\\)\nWe follow other beta regression approaches (Irvine, Rodhouse, and Keren (2016); Ferrari and Cribari-Neto (2004)) to define the parameters \\(\\alpha_{t,y}\\) and \\(\\beta_{t,y}\\) as:\n\\(\\alpha_{t,y} = \\delta_{t,y}\\phi_{t,y}\\)\n\\(\\beta_{t,y} = (1 - \\delta_{t,y})\\phi_{t,y}\\)\nIn these equations, \\(\\delta_{t,y}\\) is the mean or expected value of the biodiversity index, \\(\\bar{d}_{t,y}\\) and \\(\\phi_{t,y}\\) is a precision-type term. When \\(\\phi_{t,y}\\) is larger, the variance for \\(\\bar{d}_{t,y}\\) (\\(Var(\\bar{d}_{t,y})\\)) is smaller. \\(\\phi_{t,y}\\) is defined as:\n\\(\\phi_{t,y} = \\frac{\\delta_{t,y}(1-\\delta_{t,y})}{Var(\\bar{d}_{t,y})}-1\\)\nand \\(Var(\\bar{d}_{t,y})\\) includes both known variance from the imperfect detection model, \\(\\hat{\\sigma}^2(\\bar{d}_{t,y})\\), and unknown “process” variance, \\(\\sigma^2_{P}\\):\n\\(Var(\\bar{d}_{t,y}) = \\hat{\\sigma}^2(\\bar{d}_{t,y}) + \\sigma^2_{P}\\)\nWe set a uniform prior for the process variance, \\(\\sigma^2_{P}\\) with an upper limit that ensures that \\(\\alpha_{t,y} &gt; 0\\) and \\(\\beta_{t,y} &gt; 0\\).\nThe mean (expected) biodiversity index, \\(\\delta_{t,y}\\), is defined via a regression model:\n\\(logit(\\delta_{t,y}) = \\beta_{0,t} + \\sum_{j =1}^J\\beta_jZ_{j,t,y}\\)\nIn this regression, \\(\\beta_{0,t}\\) varies by a spatial factor by including a spatial random effect with priors that are hierarchically centered around a coarser spatial level, which is given a prior that varies around an overall community intercept (Ogle and Barber 2020). The coefficients \\(\\beta_1\\), \\(\\beta_2\\)… \\(\\beta_J\\) denote the effects of an antecedent covariate, \\(Z_{j,t,y}\\) for j = 1, 2, …,J covariates. Each covariate \\(Z_{j,t,y}\\) is the weighted average of the current value for that covariate at time y and a defined number of past values for that covariate preceding time y. We divided these into either seasonal or yearly values for that covariate (e.g., spring temperature, yearly plant biomass). The weight (“importance weight”) of each of these values, m, in the overall calculation of \\(Z_{j,t,y}\\), \\(w_{j,m}\\), is estimated by the model using the stochastic antecedent modeling framework (Ogle et al. 2015). In this modeling framework, each \\(w_{j,m}\\) is estimated using a Dirichlet prior so that the sum across all weights for that covariate equals one and more important time periods, m get higher importance weights. Thus, when a covariate effect, \\(\\beta_j\\) is significant, the weights for each time lag for that covariate informs over which timescale(s) that covariate influences biodiversity.\nWhile the process will be different for some biodiversity metrics (e.g., species richness, Shannon diversity), similar partitioning of variance can be performed for other data distributions (e.g., Poisson) by using the mean \\(E(x)\\) and variance \\(Var(x)\\) equations for any distribution.\n\n3.1.1 The model translated to JAGS code\nBelow is example JAGS code for the model specified above:\n\nmodel{\n  \n  for(i in 1:n.data){\n    \n    #-------------------------------------## \n    # Likelihood ###\n    #-------------------------------------##\n    \n    #d is dissimilarity and is proportional, so beta distribution works here\n    d[i] ~ dbeta(alpha[i], beta[i])\n      \n    #var.process is scalar but could be made dependent on site/other variables\n    #phi incorporates mu (mean estimate), var.estimate (which is from\n    #\"data\" on standard deviation (squared) from the original detection \n    #correction model) \n    #and var.process is something we're trying to estimate,\n    #basically, the rest of the variation not accounted for\n    phi[i] &lt;- (((1-mu[i])*mu[i])/(var.estimate[i] + var.process))-1\n\n    #alpha and beta are based on mu and phi values\n    #sometimes these values send alpha and beta outside\n    #the domain, so we have extra code below to get them to\n    #stay where they belong\n    alphaX[i] &lt;- mu[i] * phi[i]\n    betaX[i] &lt;- (1 - mu[i]) * phi[i]\n    \n    #here is where we get alpha and beta to stay in their\n    #domain\n    alpha[i] &lt;- max(0.01, alphaX[i])\n    beta[i] &lt;- max(0.01, betaX[i])\n    \n    #to get a good estimate of a prior for var.process, we\n    #track the difference between these two values for each\n    #data point\n    diff[i] &lt;- (1-mu[i])*mu[i] - var.estimate[i]\n\n    #Regression of mu, which is dependent on a hierrarchically-centered\n    #site random effect and the weighted antecedent effects of two covariates,\n    #plant biomass and temperature\n      logit(mu[i]) &lt;- b0.site[Site.ID[i]] +\n        b[1]*AntCov1[i] +\n        b[2]*AntCov2[i]\n      \n      #-------------------------------------## \n      # SAM summing ###\n      #-------------------------------------##\n      \n      #summing the antecedent values\n      AntCov1[i] &lt;- sum(Cov1Temp[i,]) #summing across the total number of antecedent years\n      AntCov2[i] &lt;- sum(Cov2Temp[i,]) #summing across the total num of antecedent months\n\n      #Generating each year's weight to sum above\n      for(t in 1:n.lag1){ #number of time steps we're going back in the past\n        Cov1Temp[i,t] &lt;- Cov1[i,t]*wA[t] \n      \n        #imputing missing data\n        Cov1[i,t] ~ dnorm(mu.cov1, tau.cov1)\n      }\n        \n      #generating each month's weight to sum above\n      for(t in 1:n.lag2){ #number of time steps we're going back in the past\n        Cov2Temp[i,t] &lt;- Cov2[i,t]*wB[t] \n\n        #missing data\n        Cov2[i,t] ~ dnorm(mu.cov2, tau.cov2)\n      }\n      \n      #-------------------------------------## \n      # Goodness of fit parameters ###\n      #-------------------------------------##\n      # \n      #replicated data\n      d.rep[i] ~ dbeta(alpha[i], beta[i])\n      # \n      #residuals\n      resid[i] &lt;- d[i] - mu[i]\n \n  }\n  \n  #-------------------------------------## \n  # Priors ###\n  #-------------------------------------##\n  \n  # ANTECEDENT CLIMATE PRIORS\n  #Sum of the weights for lag\n  sumA &lt;- sum(deltaA[]) #all the plant weights\n  \n  #Employing \"delta trick\" to give vector of weights dirichlet priors\n  #this is doing the dirichlet in two steps \n  #see Ogle et al. 2015 SAM model paper in Ecology Letters\n  for(t in 1:n.lag1){ #for the total number of lags\n    #the weights for kelp - getting the weights to sum to 1\n    wA[t] &lt;- deltaA[t]/sumA\n    #and follow a relatively uninformative gamma prior\n    deltaA[t] ~ dgamma(1,1)\n    \n    #to look at how weights accumulate through time\n    cumm.wt1[t] &lt;- sum(wA[1:t])\n  }\n  \n  #Sum of the weights for temp lag\n  sumB &lt;- sum(deltaB[]) #all the temp weights\n  \n  #Employing \"delta trick\" to give vector of weights dirichlet priors\n  #this is doing the dirichlet in two steps \n  #see Ogle et al. 2015 SAM model paper in Ecology Letters\n  for(t in 1:n.lag2){ #for the total number of lags\n    #the weights for kelp - getting the weights to sum to 1\n    wB[t] &lt;- deltaB[t]/sumB\n    #and follow a relatively uninformative gamma prior\n    deltaB[t] ~ dgamma(1,1)\n    \n    #to look at cummulative weigths through time\n    cumm.wt2[t] &lt;- sum(wB[1:t])\n  }\n  \n  #BETA PRIORS\n  #HIERARCHICAL STRUCTURE PRIORS\n  #hierarchical centering of sites on b0\n   for(s in 1:n.sites){\n     b0.site[s] ~ dnorm(b0, tau.site)\n   }\n  \n  #overall intercept gets relatively uninformative prior\n  b0 ~ dnorm(0, 1E-2)\n  \n  #for low # of levels, from Gelman paper - define sigma\n  # as uniform and then precision in relation to this sigma\n  sig.site ~ dunif(0, 10)\n  tau.site &lt;- 1/pow(sig.site,2)\n  \n  #covariate effects - again get relatively uninformative priors\n  for(i in 1:2){\n    b[i] ~ dnorm(0, 1E-2)\n  }\n  \n  #PRior for process error\n  var.process ~ dunif(0, min(diff[]))\n\n\n  #MISSING DATA PRIORS\n  mu.cov1 ~ dunif(-10, 10)\n  sig.cov1 ~ dunif(0, 20)\n  tau.cov1 &lt;- pow(sig.cov1, -2)\n  mu.cov2 ~ dunif(-10, 10)\n  sig.cov2 ~ dunif(0, 20)\n  tau.cov2 &lt;- pow(sig.cov2, -2)\n  \n}"
  },
  {
    "objectID": "03_community-stability-environment.html#the-model-in-action",
    "href": "03_community-stability-environment.html#the-model-in-action",
    "title": "3  Evaluating biodiversity in relation to environmental variables",
    "section": "3.2 The model in action",
    "text": "3.2 The model in action\nBecause we have greatly reduced the dimensionality of our community dataset by deriving a change metric for each site in each year, y to the next year y+1, the models run efficiently enough that we can use real data for this tutorial. We will demonstrate the utility of this model for the grasshopper dataset from Sevilleta LTER used in our examples in the paper. This LTER site also has high-resolution information for temperature, precipitation, and plant biomass.\nThis dataset has:\n\n60 communities (survey transects) which have change data for\n27 years, and we calculated\nBray-Curtis dissimilarity for this count dataset\n6 seasons of temperature and precipitation data and\n11 seasons of plant data as covariates\n\nIn this dataset, we are evaluating how Bray-Curtis dissimilarity through time is shaped by the covariates of temperature, precipitation, and plant biomass.\nAgain, to run the model in R and JAGS, we will need:\n\nThe model file\nThe data list\nA script to wrap JAGS in R\n\nYou can find all of these, along with the tidy data and script used to prep the data list for this example, in the beta regression tutorial folder\n\n3.2.1 Running the model\n\n3.2.1.1 The model file\nYou will need to provide a path to the model file (which is its own R script, written in JAGS/BUGS language, so it won’t actually run in R). You can find ours here. You will see that we define the path to this model in our model running script below.\n\n\n3.2.1.2 The data list\nTo run the model, we will need to provide JAGS with a data list, which you can find here. We have code on how to prepare the data list here.\n\ndata_list &lt;- readRDS(here('tutorials',\n                          '03_beta_regression',\n                          'data',\n                          \"model_inputs\",\n                          \"grasshopper_betareg_input_data_list.RDS\"))\n\nstr(data_list)\n\nList of 13\n $ n.data      : int 1260\n $ n.webs      : int 10\n $ n.templag   : int 6\n $ n.npplag    : int 11\n $ n.pptlag    : int 6\n $ n.transects : int 60\n $ bray        : num [1:1260] 0.26 0.261 0.283 0.339 0.425 ...\n $ var.estimate: num [1:1260] 0.00234 0.00347 0.00221 0.00204 0.00278 ...\n $ Web.ID      : num [1:1260] 1 1 1 1 1 1 1 1 1 1 ...\n $ Transect.ID : int [1:1260] 1 1 1 1 1 1 1 1 1 1 ...\n $ Temp        : num [1:1260, 1:6] -0.845 -1.009 -1.06 -1.031 -0.971 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:6] \"Temp\" \"Temp_l1\" \"Temp_l2\" \"Temp_l3\" ...\n $ PPT         : num [1:1260, 1:6] 0.771 0.534 0.499 1.148 0.211 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:6] \"PPT\" \"PPT_l1\" \"PPT_l2\" \"PPT_l3\" ...\n $ NPP         : num [1:1260, 1:11] -0.4807 -0.8532 -0.2417 0.0536 -0.8767 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:11] \"NPP\" \"NPP_l1\" \"NPP_l2\" \"NPP_l3\" ...\n\n\nAs you can see, this data list includes indexing numbers, vectors, matrices, and arrays to pass to JAGS.\n\n\n3.2.1.3 The script to run the model\nJust like with the imperfect detection model, we’ll run the model using the jagsUI wrapper package. You can find this script here, and the general code to run a JAGS model is provided here:\n\n# Load packages ---------------------------------------------------------------\n\n# Load packages, here and tidyverse for coding ease, \npackage.list &lt;- c(\"here\", \"tidyverse\", #general packages for data input/manipulation\n                  \"jagsUI\", #to run JAGS models\n                  'mcmcplots', #to look at trace plots\n                  \"coda\",'patchwork') #to evaluate convergence\n                   \n\n## Installing them if they aren't already on the computer\nnew.packages &lt;- package.list[!(package.list %in% \n                                 installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\n## And loading them\nfor(i in package.list){library(i, character.only = T)}\n\n\n# Load data ---------------------------------------------------------------\n\ndata_list &lt;- readRDS(here('tutorials',\n                          '03_beta_regression',\n                          'data',\n                          \"model_inputs\",\n                          \"grasshopper_betareg_input_data_list.RDS\"))\n\n\n# Define model path -------------------------------------------------------\n\nmodel &lt;- here('tutorials',\n              '03_beta_regression',\n              'code',\n              'grasshopper_betareg_model.R')\n\n# Parameters to save ------------------------------------------------------\n\n#these parameters we can track to assess convergence\nparams &lt;- c('b0.web', #site-level intercepts\n            'b0', #overall intercept\n            'b', #covariate effects\n            'wA', #plant biomass weights vector\n            'wB', #temperature weights\n            'sig.site', #sd of site effects\n            'var.process') #unknown variance\n\n# JAGS model --------------------------------------------------------------\n\nmod &lt;- jagsUI::jags(data = data_list,\n                    inits = NULL,\n                    model.file = model,\n                    parameters.to.save = params,\n                    parallel = TRUE,\n                    n.chains = 3,\n                    n.iter = 350,\n                    DIC = TRUE)\n\n\n# Check convergence -------------------------------------------------------\n# \nmcmcplot(mod$samples)\n# \ngelman.diag(mod$samples, multivariate = F)\n\nAgain, depending on your computer and/or datasets, you may need to re-run this model with initial values for root nodes and use cloud computing to run this model.\n\n\n\n3.2.2 Model results\nOnce you have a resulting model file (which could be quite large), you can generate a summary of it:\n\nsum &lt;- summary(mod$samples)\n\nThis model requires some re-running with initial values, which we have done and provide a summary from the converged model in the tutorial folder. We can look at estimated values from this summary to assess how temperature, precipitation, and plant biomass impact grasshopper communities.\n\n3.2.2.1 Covariate effects\n\ntheme_set(theme_bw())\n#pull median and 95% BCI out of the summary file:\nbetas &lt;- as.data.frame(sum$quantiles) %&gt;%\n  #get parameter names to be a column\n    rownames_to_column(var = \"parm\") %&gt;%\n  #select only the covariate effect betas\n    filter(str_detect(parm, \"b\")) %&gt;%\n    filter(!str_detect(parm, \"b0\")) %&gt;%\n  filter(!str_detect(parm, \"web\"))\n\n#plot these median and 95% BCI values\nggplot(betas, aes(x = `50%`, y = parm)) +\n  geom_vline(xintercept = 0, linetype = 2, alpha = 0.4) +\n  geom_pointrange(aes(x = `50%`,\n                      y = parm, \n                      xmin = `2.5%`,\n                      xmax = `97.5%`),\n                  size = 0.4) +\n  scale_y_discrete(labels = c(\"Temperature\", \"Precipitation\",\n                              'Plant biomass')) + \n  labs(x = \"Covariate effect \\n (Median and 95% BCI)\",\n       y = \"\") +\n  theme_bw()\n\n\n\n\nThis figure suggests that there is a clear effect of all three covariates on Bray-Curtis dissimilarity. Higher temperatures and plant biomass lead to higher community change; higher precipitation leads to lower community change. We can then look at which seasons drive these effects:\n\n#pull the median and 95% BCI weights for temperature out of the model summary file\nhopper_weights &lt;- as.data.frame(sum$quantiles) %&gt;%\n  rownames_to_column(var = \"par\") %&gt;%\n  filter(str_detect(par, \"w\")) %&gt;%\n  filter(!str_detect(par, \"cumm\")) %&gt;%\n  filter(!str_detect(par, \"b0.web\")) %&gt;%\n  filter(!str_detect(par, \"sig.web\")) %&gt;%\n  mutate(lag = str_sub(par, 4, (nchar(par)-1))) %&gt;%\n  mutate(covariate = case_when(str_detect(par, \"wA\") ~ \"Temperature\",\n                               str_detect(par, \"wB\") ~ \"Precipitation\",\n                               str_detect(par, \"wC\") ~ \"Plant biomass\")) %&gt;%\n  dplyr::select(lag, covariate, `2.5%`, `50%`, `97.5%`)\n\nhop_weight_plot1 &lt;- hopper_weights %&gt;%\n    filter(covariate == \"Plant biomass\") %&gt;%\n    mutate(lag = factor(lag, levels = c(\"1\", \"2\", \n                                        \"3\", \"4\", \"5\",\n                                        \"6\", \"7\", \"8\",\n                                        \"9\", \"10\",\n                                        \"11\"))) %&gt;%\n    ggplot(aes(x = lag, y = `50%`)) +\n    geom_hline(yintercept = 1/11, linetype = 2, alpha = 0.4) +\n    geom_pointrange(aes(x = lag, \n                        y = `50%`,\n                        ymin = `2.5%`,\n                        ymax = `97.5%`),\n                    position=position_dodge(width=0.5),\n                    size = 0.4) +\n    facet_grid(~covariate)+\n    labs(x= \"Seasons into past\",\n         y = \"Importance weight\\n(median and 95% BCI)\")\n\nhop_weight_plot2 &lt;- hopper_weights %&gt;%\n    filter(covariate != \"Plant biomass\") %&gt;%\n    mutate(lag = factor(lag, levels = c(\"1\", \"2\", \n                                        \"3\", \"4\", \"5\",\n                                        \"6\"))) %&gt;%\n    ggplot(aes(x = lag, y = `50%`)) +\n    geom_hline(yintercept = 1/6, linetype = 2, alpha = 0.4) +\n    geom_pointrange(aes(x = lag, \n                        y = `50%`,\n                        ymin = `2.5%`,\n                        ymax = `97.5%`),\n                    position=position_dodge(width=0.5),\n                    size = 0.4) +\n    facet_grid(~covariate)+\n    labs(x= \"Seasons into past\",\n         y = \"Importance weight\\n(median and 95% BCI)\") +\n  theme(axis.title.y = element_blank())\n\nhop_weight_plot1 +hop_weight_plot2 +\n  plot_layout(widths = c(1.5,2))\n\n\n\n\nThe dashed line indicates the values of importance weights if they were all equal (their prior weights). Any values clearly above this line indicate more important seasons. For plant biomass, we can see that there aren’t any clearly more important seasons, though some suggestion that more current seasons and seasons 2 years ago may be more important. For precipitation, it appears that this season is most important, but there may be a longer temporal signal if we added more time lags (when the current “wet” season is more wet, there is less community change). For temperature, last “warm” season (the season before the current one) is most important (when the previous warm season is warmer, there is more community change)."
  },
  {
    "objectID": "03_community-stability-environment.html#wrapping-up",
    "href": "03_community-stability-environment.html#wrapping-up",
    "title": "3  Evaluating biodiversity in relation to environmental variables",
    "section": "3.3 Wrapping up",
    "text": "3.3 Wrapping up\nFor all models, you will want to be able to describe some kind of goodness-of-fit metric. We do this by replicating data in the model (e.g., d.rep in the model above) and then comparing the relationship between replicated data and observed data using a simple linear regression (Conn et al. 2018).\n\n\n\n\nConn, Paul B., Devin S. Johnson, Perry J. Williams, Sharon R. Melin, and Mevin B. Hooten. 2018. “A Guide to Bayesian Model Checking for Ecologists.” Ecological Monographs 88 (4): 526–42. https://doi.org/10.1002/ecm.1314.\n\n\nFerrari, Silvia, and Francisco Cribari-Neto. 2004. “Beta Regression for Modelling Rates and Proportions.” Journal of Applied Statistics 31 (7): 799–815. https://doi.org/10.1080/0266476042000214501.\n\n\nIrvine, Kathryn M., T. J. Rodhouse, and Ilai N. Keren. 2016. “Extending Ordinal Regression with a Latent Zero-Augmented Beta Distribution.” Journal of Agricultural, Biological and Environmental Statistics 21 (4): 619–40. https://doi.org/10.1007/s13253-016-0265-2.\n\n\nOgle, Kiona, and Jarrett J. Barber. 2020. “Ensuring Identifiability in Hierarchical Mixed Effects Bayesian Models.” Ecological Applications 30 (7): e02159. https://doi.org/10.1002/eap.2159.\n\n\nOgle, Kiona, Jarrett J. Barber, Greg A. Barron-Gafford, Lisa Patrick Bentley, Jessica M. Young, Travis E. Huxman, Michael E. Loik, and David T. Tissue. 2015. “Quantifying Ecological Memory in Plant and Ecosystem Processes.” Edited by Elsa Cleland. Ecology Letters 18 (3): 221–35. https://doi.org/10.1111/ele.12399."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Conn, Paul B., Devin S. Johnson, Perry J. Williams, Sharon R. Melin, and\nMevin B. Hooten. 2018. “A Guide to Bayesian Model Checking for\nEcologists.” Ecological Monographs 88 (4): 526–42. https://doi.org/10.1002/ecm.1314.\n\n\nDorazio, Robert M., Andrew Royle, Bo Soderstrom, and Anders Glimskar.\n2006. “Estimating Species Richness and Accumulation by Modeling\nSpecies Occurence and Detectability.” Ecology 87 (4):\n842–54. https://doi.org/10.1890/0012-9658(2006)87[842:ESRAAB]2.0.CO;2.\n\n\nFerrari, Silvia, and Francisco Cribari-Neto. 2004. “Beta\nRegression for Modelling Rates and Proportions.” Journal of\nApplied Statistics 31 (7): 799–815. https://doi.org/10.1080/0266476042000214501.\n\n\nGrenié, M, and H Gruson. 2025. Fundiversity: Easy Computation of\nFunctional Diversity Indices. https://CRAN.R-project.org/package=fundiversity.\n\n\nHallett, Lauren M., Sydney K. Jones, A. Andrew M. MacDonald, Matthew B.\nJones, Dan F. B. Flynn, Julie Ripplinger, Peter Slaughter, Corinna\nGries, and Scott L. Collins. 2016. “Codyn: Anrpackage of Community\nDynamics Metrics.” Edited by Timothée Poisot. Methods in\nEcology and Evolution 7 (10): 1146–51. https://doi.org/10.1111/2041-210x.12569.\n\n\nIrvine, Kathryn M., T. J. Rodhouse, and Ilai N. Keren. 2016.\n“Extending Ordinal Regression with a Latent Zero-Augmented Beta\nDistribution.” Journal of Agricultural, Biological and\nEnvironmental Statistics 21 (4): 619–40. https://doi.org/10.1007/s13253-016-0265-2.\n\n\nMorris, E. Kathryn, Tancredi Caruso, François Buscot, Markus Fischer,\nChristine Hancock, Tanja S. Maier, Torsten Meiners, et al. 2014.\n“Choosing and Using Diversity Indices: Insights for Ecological\nApplications from the German Biodiversity Exploratories.”\nEcology and Evolution 4 (18): 3514–24. https://doi.org/10.1002/ece3.1155.\n\n\nOgle, Kiona, and Jarrett J. Barber. 2020. “Ensuring\nIdentifiability in Hierarchical Mixed Effects Bayesian Models.”\nEcological Applications 30 (7): e02159. https://doi.org/10.1002/eap.2159.\n\n\nOgle, Kiona, Jarrett J. Barber, Greg A. Barron-Gafford, Lisa Patrick\nBentley, Jessica M. Young, Travis E. Huxman, Michael E. Loik, and David\nT. Tissue. 2015. “Quantifying Ecological Memory in Plant and\nEcosystem Processes.” Edited by Elsa Cleland. Ecology\nLetters 18 (3): 221–35. https://doi.org/10.1111/ele.12399.\n\n\nOksanen, Jari, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt,\nPierre Legendre, Dan McGlinn, Peter R. Minchin, et al. 2020. Vegan:\nCommunity Ecology Package. https://CRAN.R-project.org/package=vegan."
  }
]