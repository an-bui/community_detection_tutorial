[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Imperfect detection and community change: a modeling tutorial",
    "section": "",
    "text": "Preface"
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Imperfect detection and community change: a modeling tutorial",
    "section": "Description",
    "text": "Description\nThis is a modeling tutorial for the supplement for Miller-ter Kuile et al. “Accounting for imperfect detection to reveal the importance of current and past environmental conditions for community stability”. in revision\nThe purpose of this tutorial is to provide a detailed description of the modeling approaches used in the paper along with examples of the models in action on both simulated and real datasets."
  },
  {
    "objectID": "index.html#case-studies",
    "href": "index.html#case-studies",
    "title": "Community detection tutorial",
    "section": "Case studies",
    "text": "Case studies\n[describe four datasets here]",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html",
    "href": "01_accounting-for-imperfect-detection.html",
    "title": "1  Accounting for imperfect detection",
    "section": "",
    "text": "Accounting for imperfect detection using Bayesian multi-species model (for either count or detection/non-detection)\n[look in supporting info for more]"
  },
  {
    "objectID": "02_computing-indices.html",
    "href": "02_computing-indices.html",
    "title": "2  Computing indices of community stability",
    "section": "",
    "text": "Measured community change (“stability”) through time\nchange in species presence/absence\nor change in BC dissimilarity\ncalculated posterior means and SD values for each change metric for each site and year\nused posterior means and standard deviation values in part 3",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Computing indices of community stability</span>"
    ]
  },
  {
    "objectID": "03_community-stability-environment.html",
    "href": "03_community-stability-environment.html",
    "title": "3  Evaluating community stability in relation to environmental variables",
    "section": "",
    "text": "compiled abiotic and biotic variables that could influence community change\nDetermine whether responses to abiotic and biotic factors are instantaneous or lagged using Bayesian regression with stochastic antecedent modeling\nmodel structure",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Evaluating community stability in relation to environmental variables</span>"
    ]
  },
  {
    "objectID": "04_imperfect-detection.html",
    "href": "04_imperfect-detection.html",
    "title": "4  How imperfect detection shapes community change estimates across datasets",
    "section": "",
    "text": "assessed how accounting for imperfect detection influenced estimates of community change by comparing observed and modeled estimates of dissimilarity\nfirst creating observed dataset based on multiple sampling events per year\nthen created an observed dataset based on one sampling event per year\nexamined differences between observed datasets by using Bayesian hierarchical regression with change as response and data derivation crossed with dataset as predictor\npost-hoc pairwise tests to determine direction and magnitude of differences",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>How imperfect detection shapes community change estimates across datasets</span>"
    ]
  },
  {
    "objectID": "index.html#tools-youll-need",
    "href": "index.html#tools-youll-need",
    "title": "Imperfect detection and community change: a modeling tutorial",
    "section": "Tools you’ll need",
    "text": "Tools you’ll need\nAll models are Bayesian models run in R and JAGS. You will need these programs to run these models.\nDownload R\n(We also recommend RStudio)\nDownload JAGS"
  },
  {
    "objectID": "index.html#outline",
    "href": "index.html#outline",
    "title": "Imperfect detection and community change: a modeling tutorial",
    "section": "Outline",
    "text": "Outline\nIn the following pages, we will walk you through the model formulation as well as model code demonstrating the modeling framework.\n\nAccounting for imperfect detection walks through accounting for imperfect detection in a multi-species model\nComputing indices of community stability illustrates how latent values from the models for imperfect detection can be used to calculate multiple indices of community stability (beta diversity)\nEvaluating community stability in relation to environmental variables shows how to take these derived values of community change and uncertainty around them and use them in a regression that allows covariates to have immediate and lagged effects on community change\n\n\n\n\n\nDorazio, Robert M., Andrew Royle, Bo Soderstrom, and Anders Glimskar. 2006. “Estimating Species Richness and Accumulation by Modeling Species Occurence and Detectability.” Ecology 87 (4): 842–54. https://doi.org/10.1890/0012-9658(2006)87[842:ESRAAB]2.0.CO;2.\n\n\nOgle, Kiona, Jarrett J. Barber, Greg A. Barron-Gafford, Lisa Patrick Bentley, Jessica M. Young, Travis E. Huxman, Michael E. Loik, and David T. Tissue. 2015. “Quantifying Ecological Memory in Plant and Ecosystem Processes.” Edited by Elsa Cleland. Ecology Letters 18 (3): 221–35. https://doi.org/10.1111/ele.12399."
  },
  {
    "objectID": "index.html#model-description",
    "href": "index.html#model-description",
    "title": "Imperfect detection and community change: a modeling tutorial",
    "section": "Model description",
    "text": "Model description\nWe employed a two-step modeling process (Figure 1).\n\n\n\nFigure 1: Depiction of the two-step modeling process, including A) accounting for imperfect detection using a multi-species occupancy or abundance model and B) using derived quantitites of community change along with their uncertainty in a regression examining current and past environmental drivers of change.\n\n\n\nA) Multi-species model accounting for imperfect detection\nThis model links observed abundance or presence-absence of species in a community to detection probabilities to generate a latent “true” abundance or occupancy for each species in each site in each year. We used this model to then generate metrics of community change (beta diversity). We built these models based on previous model developments for accounting for imperfect detection in community datasets (Dorazio et al. 2006).\n\n\nB) Regression model with environmental covariates\nThis model incorporates mean and variance of community change metrics from the model in A) into a regression examining the effects of environmental covariates on community change. This model employs a stochastic antecedent modeling (SAM) framework (Ogle et al. 2015) to allow environmental covariates to have immediate and lagged responses."
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html#model-formulation",
    "href": "01_accounting-for-imperfect-detection.html#model-formulation",
    "title": "1  Accounting for imperfect detection",
    "section": "1.1 Model Formulation",
    "text": "1.1 Model Formulation\nTraditional multi-species abundance (MSAM) and occupancy (MSOM) models (Dorazio et al. 2006) are built on several data requirements and assumptions:\n\nSites are visited more than once within a year, so that repeat visits can be used to estimate detection probabilities.\nThere is “closure” within a year at a site, which means species are neither gained or lost from a site within that year.\n\nThese models have two components, including a) a biological process linking latent “true” abundance or occupancy to an expected value or probability, which could depend on covariates and b) an observation process linking observed data to detection probability and “true” abundance or occupancy.\n\n1.1.1 Data distribution\nIn all following mathematical descriptions and models, subscripts are as follows:\n\ns : species\nt : survey unit (e.g., transect, quadrat)\ny : year\nr : survey replicate\n\nFor abundance models, observed data, \\(y_{s,t,y,r}\\), is dependent on detection probability, \\(p_{s,t,y,r}\\), and “true” latent abundance, \\(N_{s,t,y}\\):\n\\(y_{s,t,y,r} \\sim Binomial(p_{s,t,y,r}, N_{s,t,y})\\)\nFor occupancy models, observed data, \\(y_{s,t,y,r}\\), is dependent on detection probability, \\(p_{s,t,y,r}\\), and “true” latent occupancy, \\(z_{s,t,y}\\) (\\(z_{s,t,y}\\) = 1: presence; \\(z_{s,t,y}\\) = 0: absence):\n\\(y_{s,t,y,r} \\sim Bernoulli(p_{s,t,y,r}* z_{s,t,y})\\)\n\n\n1.1.2 Biological process\nFor abundance models, latent abundance, \\(N_{s,t,y}\\), is dependent on a rate parameter \\(\\lambda_{s,t,y}\\):\n\\(N_{s,t,y} \\sim Poisson(\\lambda_{s,t,y})\\)\nWhich, in our models, is dependent on a regression that includes a species-specific intercept and random effects of site within species and year within species which are made identifiable based on the post-sweeping method described in (Ogle and Barber 2020):\n\\(log(\\lambda_{s,t,y}) = \\beta_{0s} + \\epsilon_{s,t} + \\gamma_{s,y}\\)\nSimilarly, for occupancy models, \\(z_{s,t,y}\\) is dependent on occupancy probability, \\(\\psi_{s,t,y}\\):\n\\(z_{s,t,y} \\sim Bernoulli(psi_{s,t,y})\\)\nWhich is dependent on a similar regression:\n\\(logit(\\psi_{s,t,y}) = \\beta_{0s} + \\epsilon_{s,t} + \\gamma_{s,y}\\)\nAll species-level intercept values receive priors centered around community-level hyperparameters:\n\\(\\beta_{0s} \\sim Normal(\\mu_\\beta, \\sigma_\\beta)\\)\nWith vague or relatively uninformative priors:\n\\(\\mu_\\beta \\sim Normal(0, 1000)\\)\n\\(\\sigma_\\beta \\sim Uniform(0, 50)\\)\n\n\n1.1.3 Observation process\nFor both abundance and occupancy models, the observation process estimates detection probabilities, \\(p_{s,t,y,r}\\), which can be estimated based on a regression:\n\\(logit(p_{s,t,y,r}) = \\alpha_{0s} + \\sum_{j=1}^{J}\\alpha_jX_{j,s,t,y,r}\\)\nWhere \\(\\alpha_{0s}\\) is a species-level intercept and the coefficients \\(\\alpha_1\\), \\(\\alpha_2\\)… \\(\\alpha_J\\) denote the effect of each detection covariate \\(X_{j,s,t,y,r}\\) for j = 1, 2, … J. Each detection covariate, \\(X_{j,s,t,y,r}\\), can depend on any combination of species, site, year, and replicate (e.g., species traits would be an \\(X_s\\) whereas conditions during a survey might be a \\(X_{t,y,r}\\)).\nAgain, all species-level intercept values receive priors centered around community-level hyperparameters:\n\\(\\alpha_{0s} \\sim Normal(\\mu_\\alpha, \\sigma_\\alpha)\\)\nWith vague or relatively uninformative priors:\n\\(\\mu_\\alpha \\sim Normal(0, 1000)\\)\n\\(\\sigma_\\alpha \\sim Uniform(0, 50)\\)\nAll continous covariate effects got relatively uninformative priors\n\\(\\alpha_j \\sim Normal(0, 1000)\\)\nAnd categorical covariate effects were cell-referenced with the baseline level being that with the most observations (baseline level gets a prior value = 0, all others get uninformative normal priors similar to \\(alpha_j\\), above).\n\n\n1.1.4 The model translated to JAGS code\nBelow is example JAGS code for the model specified above:\n\nmodel{\n  \n  #Example MSAM model for tutorial with simulated data\n  \n  \n  for(s in 1:n.species){ #species\n    for(t in 1:n.transects){ #transects\n      for(y in n.start[t]:n.end[t]){ #years\n        #setting these start and end years to depend on transect\n        #allows them to vary by transect\n        \n        #BIOLOGICAL MODEL \n        \n        #expected number of individuals of species s\n        #in site t in time y is dependent on \n        #a rate parameter, lambda, for a poisson distribution\n        N[s,t,y] ~ dpois(lambda[s,t,y])\n        \n        #this rate parameter is dependent on a regression\n        #with a species intercept,\n        #and species within site, and species within year \n        #random effects (post-sweeping code is below for this )\n        log(lambda[s,t,y]) &lt;- b0.species[s] + \n          eps.site[Site.ID[t], s] +\n          eps.year[Year.ID[y], s]\n        \n        for(r in 1:n.rep[t,y]){ #for the number of surveys on each transect\n          #in each year\n          \n          # OBSERVATION MODEL\n          \n          #detection probability for species s in site t in\n          #year y in replicate r\n          logit(p[s,t,y,r]) &lt;- a0[s] + #species-level intercept\n            #a covariate that is related to the survey \n            #(e.g., weather, survey length)\n            #dependent on site, year, and replicate, but not species\n            a1*survey.covariate[t,y,r] #+\n          #could also add species covariates \n          #(e.g., body size, color, call frequency)\n            #a2*species.covariate[s]\n          \n          #abundance is binomial based on detection probability\n          #and total true abundance at the site\n          y[s,t,y,r] ~ dbin(p[s,t,y,r], N[s,t,y])\n          \n          #create replicate data based on model estimation to\n          #look at goodness-of-fit (regress y.rep ~ y)\n          y.rep[s,t,y,r] ~ dbin(p[s,t,y,r], N[s,t,y])\n          \n        }\n      }\n    }\n    \n    #SPECIES-LEVEL PRIORS:\n    #Detection intercept and slopes for each species\n    #are centered on community-level hyperpriors\n    a0[s] ~ dnorm(mu.a0,tau.a0)\n    \n    #\"baseline\" detection at vis = 0 and size = 0 \n    #on standardized scale\n    p0[s] &lt;- ilogit(a0[s])\n    \n    #species-level intercept - \n    #currently non-identifiable:\n    b0.species[s] ~ dnorm(mu.b0species, tau.b0species)\n    \n    #compute the identifiable species-level intercept:\n    #TRACK THIS ONE for convergence\n    b0.star[s] &lt;- b0.species[s] + ave.eps.site[s] + ave.eps.year[s]\n    \n  }\n  \n  #SITE W/IN SPECIES RANDOM EFFECTS\n  #sites nested within species (sites sum to zero w/in each species)\n  for(s in 1:n.species){\n    for(t in 1:n.sites){\n      #non-identifiable random effect\n      eps.site[t,s] ~ dnorm(0, tau.eps.site)\n      #identifiable site random effect (monitor this)\n      eps.site.star[t,s] &lt;- eps.site[t,s] - ave.eps.site[s]\n    }\n    #mean site level random effects within each species\n    ave.eps.site[s] &lt;- mean(eps.site[,s])\n  }\n  \n  #YEARS W/IN SPECIES RANDOM EFFECTS\n  #sites nested within species (sites sum to zero w/in each species)\n  for(s in 1:n.species){\n    for(y in 1:n.years){\n      #non-identifiable random effect\n      eps.year[y,s] ~ dnorm(0, tau.eps.year)\n      #identifiable year random effect (monitor this)\n      eps.year.star[y,s] &lt;- eps.year[y,s] - ave.eps.year[s]\n    }\n    #mean year level random effects within each species\n    ave.eps.year[s] &lt;- mean(eps.year[,s])\n  }\n  \n  #COMMUNITY HYPER PRIORS\n  #initial occupancy\n  #Detection intercept\n  mu.a0 ~ dnorm(0, 0.001)\n  tau.a0 &lt;- pow(sig.a0, -2)\n  sig.a0 ~ dunif(0, 50)\n  \n  #species-level abundance\n  mu.b0species ~ dnorm(0, 0.001)\n  tau.b0species &lt;- pow(sig.b0species, -2)\n  sig.b0species ~ dunif(0,50)\n  \n  #site and year variances\n  sig.eps.site ~ dunif(0, 10)\n  tau.eps.site &lt;- pow(sig.eps.site, -2)\n  sig.eps.year ~ dunif(0, 10)\n  tau.eps.year &lt;- pow(sig.eps.year, -2)\n  \n  #detection covariate effect priors\n  a1 ~ dnorm(0, 0.001)\n  #a2 ~ dnorm(0, 0.001)\n  \n  #IN CASE OF missing data \n  #If detection covariate data are missing, this will\n  #impute based on mean and variance of that variable\n  for(t in 1:n.transects){\n    for(y in n.start[t]:n.end[t]){\n      for(r in 1:n.rep[t,y]){\n        \n        survey.covariate[t,y,r] ~ dnorm(mu.surveycov, tau.surveycov)\n      }\n    }\n  }\n  \n  #PRIORS FOR IMPUTING MISSING DATA\n  #Priors for mean and tau of missing covariates in the model\n  mu.surveycov ~ dunif(-10, 10)\n  sig.surveycov ~ dunif(0, 20)\n  tau.surveycov &lt;- pow(sig.surveycov, -2)\n\n  #END MODEL\n}"
  },
  {
    "objectID": "01_accounting-for-imperfect-detection.html#the-model-in-action",
    "href": "01_accounting-for-imperfect-detection.html#the-model-in-action",
    "title": "1  Accounting for imperfect detection",
    "section": "1.2 The model in action",
    "text": "1.2 The model in action\nThese models take a long time to run and we utilized cloud computing to run them on real datasets. For illustration purposes, we have simulated a dataset with a small number of species, years, and survey units to illustrate how to run the model in JAGS and R.\nOur simulated dataset includes abundance data for:\n\n10 species from\n3 transects that come from\n1 site in\n5 years that all received\n2 surveys within each year\n\nIn this dataset, detection probability depends on a survey covariate that is different for each survey replicate at each site in each year (e.g., could be differences in survey length or weather during the survey).\nTo run the model in R and JAGS, we will need:\n\nThe model file\nThe data list\nA script to wrap JAGS in R\n\nYou can find all of these, along with the data simulation and tidy version of the simulated data used in this tutorial, in the MSAM tutorial folder.\n\n1.2.1 Running the model\n\n1.2.1.1 The model file\nYou will need to provide a path to the model file (which is its own R script, written in JAGS/BUGS language, so it won’t actually run in R). You can find ours here. You will see that we define the path to this model in our model running script below.\n\n\n1.2.1.2 The data list\nTo run the model, we will need to provide JAGS with a data list, which you can find here. We have code on how to prepare the data list here.\n\ndata_list &lt;- readRDS(here('tutorials',\n                          \"MSAM\",\n                          'data',\n                          'model_inputs',\n                          'MSAM_data_list.RDS'))\n\nstr(data_list)\n\nList of 11\n $ Site.ID         : num [1:3] 1 1 1\n $ Year.ID         : int [1:5] 1 2 3 4 5\n $ survey.covariate: num [1:3, 1:5, 1:2] -0.626 1.512 0.919 -0.836 -0.621 ...\n $ count           : num [1:5, 1:3, 1:5, 1:2] 23 0 1 0 14 24 1 1 1 31 ...\n $ n.species       : num 5\n $ n.transects     : num 3\n $ n.sites         : num 1\n $ n.years         : num 5\n $ n.start         : num [1:3] 1 1 1\n $ n.end           : num [1:3] 5 5 5\n $ n.rep           : num [1:3, 1:5] 2 2 2 2 2 2 2 2 2 2 ...\n\n\nAs you can see, this data list includes indexing numbers, vectors, matrices, and arrays to pass to JAGS.\n\n\n1.2.1.3 The script to run the model\nWe’ll run the model using the jagsUI wrapper package. You can find this script here, and the general code to run a JAGS model is provided here:\n\n# Load packages -----------------------------------------------------------\n\n\npackage.list &lt;- c(\"tidyverse\", 'here', #general packages\n                  'jagsUI', #jags wrapper\n                  'coda', #gelman.diag() function\n                  'mcmcplots') #trace plot function\n\n## Installing them if they aren't already on the computer\nnew.packages &lt;- package.list[!(package.list %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\n## And loading them\nfor(i in package.list){library(i, character.only = T)}\n\n# Load data -----------------------------------------------------------\n\ndata_list &lt;- readRDS(here('tutorials',\n                          \"MSAM\",\n                          'data',\n                          'model_inputs',\n                          'MSAM_data_list.RDS'))\n\n# Define model path -----------------------------------------------------------\n\n#The model file is here:\nmodel_file &lt;- here('tutorials',\n                   \"MSAM\",\n                   'code',\n                   'MSAM_model.R')\n\n# Specify parameters to save -----------------------------------------------------------\n\n#These are the parameters we will want to track \n#to assess convergence\nparameters &lt;- c('b0.star',\n                'a0',\n                'a1',\n                'eps.site.star',\n                'eps.year.star',\n                'mu.a0',\n                'sig.a0',\n                'mu.b0species',\n                'sig.b0species',\n                'sig.eps.site',\n                'sig.eps.year')\n\n# Set initial values for model -----------------------------------------------------------\n\n#this was also generated when we simulated data - it aids in \n#convergence when we have known values\ninits_list &lt;- readRDS(here('tutorials',\n                           \"MSAM\",\n                           'data',\n                           \"model_inputs\",\n                           'MSAM_inits_list.RDS'))\n\n#IMPORTANT: You will need to set initial values for the number of \n#individuals (N), which will keep the model from running into errors\n#when a sampled number in the distribution exceeds the maximum\n#number observed at that site\n\n#We can also set initial values for various variables \n# with known values to get convergence faster, but these are not\n#necessary to get the model to run\ninits &lt;- list(list(a1 = inits_list$a1,\n                   mu.a0 = inits_list$mu.a0,\n                   mu.b0species = inits_list$mu.b0species,\n                   a0 = inits_list$a0,\n                   b0.species = inits_list$b0.species,\n                   eps.site = inits_list$eps.site,\n                   eps.year = inits_list$eps.year,\n                   N = inits_list$countmax),\n              list(a1 = inits_list$a1 + 0.05,\n                   mu.a0 = inits_list$mu.a0 + 0.05,\n                   mu.b0species = inits_list$mu.b0species + 0.05,\n                   a0 = inits_list$a0 + 0.05,\n                   b0.species = inits_list$b0.species + 0.05,\n                   eps.site = inits_list$eps.site + 0.05,\n                   eps.year = inits_list$eps.year + 0.05,\n                   N = inits_list$countmax),\n              list(a1 = inits_list$a1 - 0.05,\n                   mu.a0 = inits_list$mu.a0 - 0.05,\n                   mu.b0species = inits_list$mu.b0species - 0.05,\n                   a0 = inits_list$a0 - 0.05,\n                   b0.species = inits_list$b0.species - 0.05,\n                   eps.site = inits_list$eps.site - 0.05,\n                   eps.year = inits_list$eps.year - 0.05,\n                   N = inits_list$countmax))\n\n# Run the model -----------------------------------------------------------\n\n#run the model \nmodel &lt;- jagsUI::jags(data = data_list,\n                      inits = inits,\n                      parameters.to.save = parameters,\n                      model.file = model_file,\n                      parallel = TRUE,\n                      n.chains = 3,\n                      n.iter = 1335,\n                      DIC = TRUE)\n\n# Assess convergence -----------------------------------------------------------\n\n#assess convergence with Gelman statistic\ngelman.diag(model$samples, multivariate = F)\n#generate trace plots\nmcmcplot(model$samples)\n\nWe have run this just for enough iterations to assess convergence (it likely hasn’t converged) so that we can provide the model output for downstream tutorial steps. For your own datasets, you may need to keep running this model a few times for more iterations than we’ve shown above, resetting initial values based on new model runs to get this model to converge. For the datasets we evaluated in our manuscript, we set a convergence cutoff of &gt;95% of all nodes converging at Gelman diagnostic (\\(\\hat{R} \\leq 1.2\\)).\n\n\n\n1.2.2 Next: using N to compute indices of community stability\nNext up, we’ll use estimates of N for each species in each site in each year to calculate an index of community stability (beta diversity)!\n\n\n\n\nDorazio, Robert M., Andrew Royle, Bo Soderstrom, and Anders Glimskar. 2006. “Estimating Species Richness and Accumulation by Modeling Species Occurence and Detectability.” Ecology 87 (4): 842–54. https://doi.org/10.1890/0012-9658(2006)87[842:ESRAAB]2.0.CO;2.\n\n\nOgle, Kiona, and Jarrett J. Barber. 2020. “Ensuring Identifiability in Hierarchical Mixed Effects Bayesian Models.” Ecological Applications 30 (7): e02159. https://doi.org/10.1002/eap.2159."
  },
  {
    "objectID": "02_computing-indices.html#computing-indices-of-community-stability",
    "href": "02_computing-indices.html#computing-indices-of-community-stability",
    "title": "2  Computing indices of community stability",
    "section": "2.1 Computing indices of community stability",
    "text": "2.1 Computing indices of community stability\n\n2.1.1 Bray-Curtis Dissimilarity\nBray-Curtis dissimilarlity describes changes in overall community abundance across time or space. This index is calculated by breaking the two communities being compared into three parts:\n\nThe total number of shared individuals in communities 1 and 2 (A)\nThe total number of individuals in only community 1 (B)\nThe total number of individuals in only community 2 (C)\n\nThen, dissimilarlity is calcluated as:\n\\(BC = \\frac{(B + C)}{(2A + B + C)}\\)\n\n\n2.1.2 Species turnover\nSpecies turnover is similar to Bray-Curtis dissimilarity - we break the two communities into three different groups:\n\nThe species shared between community 1 and 2 (A)\nThe species only in community 1 (B)\nThe species only in community 2 (C)\n\nThen, turnover is:\n\\(turnover = \\frac{(B + C)}{(A + B + C)}\\)\n\n\n2.1.3 Interpretting both metrics\nIn both metrics, values closer to 1 indicate that the two communities are more different (a larger fraction of individuals or species are different between communities 1 and 2 than are shared). In our case, we are calculating these change metrics between a given survey unit in a dataset (“community”) between adjacent timepoints. For most datasets, this means we are comparing communities in time y to time y+1. However, for one dataset (PFNP plants), survey intervals were &gt; 1 year apart, so we compared communities between adjacent time points (e.g. 2007 and 2014, 2014 and 2021).\n\n\n2.1.4 Notation in our paper\nIn the paper, we define a general dissimilarity metric as \\(d_{t,y}\\). And use the mean (\\(\\bar{d}_{t,y}\\)) and variance (\\(Var(\\bar{d}_{t,y})\\)) of this value as “data” in the environmental regression model."
  },
  {
    "objectID": "02_computing-indices.html#dissimilarity-metrics-in-jags-models",
    "href": "02_computing-indices.html#dissimilarity-metrics-in-jags-models",
    "title": "2  Computing indices of community stability",
    "section": "2.2 Dissimilarity metrics in JAGS models",
    "text": "2.2 Dissimilarity metrics in JAGS models\n\n2.2.1 Model code\nWe included these metrics as “derived quantities” in our MSAM models that we then pulled from models after they had converged. You can also derive these quantities in R, which we did for the PFNP plant dataset and code to do so can be found here\nThese derived quantities come at the end of the model code that we highlighted in the previous step (“Accounting for imperfect detection”), but we do not provide the whole model here for brevity. To see the model with both components, you can look at our model file in the MSAM tutorial folder.\n\nmodel{\n  \n  #...\n  #This is all the model code that we provided in the \n  # \"Accounting for Imperfect Detection\" tab, so we do not provide it here, \n  #for brevity.\n  \n  #DERIVED QUANTIIES\n  \n  #Bray-Curtis dissimilarity\n  for(t in 1:n.transects){\n    for(y in (n.start[t]+1):n.end[t]){\n      for(s in 1:n.species){\n        # num individuals in both time periods per species\n        a[s,t,y] &lt;- min(N[s,t,y-1], N[s,t,y])\n        # num individuals only in first time point\n        b[s,t,y] &lt;- N[s,t,y-1] - a[s,t,y]\n        # num individuals only in second time point\n        c[s,t,y] &lt;- N[s,t,y] - a[s,t,y]\n      }\n      #for all years 2 onward:\n      #total number of shared individuals across time periods\n      A[t,y] &lt;- sum(a[,t,y])\n      #total number of individuals in only first time period\n      B[t,y] &lt;- sum(b[,t,y])\n      #total number of individuals in only second time period\n      C[t,y] &lt;- sum(c[,t,y])\n      \n      #total bray-curtis (B+C)/(2A+B+C)\n      num[t,y] &lt;- B[t,y] + C[t,y]\n      denom1[t,y] &lt;- 2*A[t,y]+B[t,y]+C[t,y]\n      #if all values are zero - this just keeps the eqn. from\n      #dividing by zero\n      denom[t,y] &lt;- ifelse(denom1[t,y]==0,1, denom1[t,y])\n      \n      #Calculate Bray-Curtis dissimiarlity\n      bray[t,y] &lt;- num[t,y]/denom[t,y]\n      \n    }\n  }\n}\n\n\n\n2.2.2 Updating the model to get change metrics\nWe updated our converged model for a short number of iterations to get good estimates of mean and standard deviation values for our change metrics. We then exported the mean and standard deviations for these metrics as “data” to be provided in the next model (Evaluating community stability in relation to environmental variables)\n\n# Load packages -----------------------------------------------------------\n\npackage.list &lt;- c(\"tidyverse\", 'here', #general packages\n                  'jagsUI') #jags wrapper\n\n## Installing them if they aren't already on the computer\nnew.packages &lt;- package.list[!(package.list %in% installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\n## And loading them\nfor(i in package.list){library(i, character.only = T)}\n\n# Load converged model -----------------------------------------------------------\n\nmodel &lt;- readRDS(here('tutorials',\n                      \"MSAM\",\n                      'data',\n                      'model_outputs',\n                      'MSAM_model_output.RDS'))\n\n# Update model to track Bray-Curtis ------------------------------------------------\n\n#now the parameter we want is just bray, none of the others\nparams2 &lt;- c(\"bray\")\n\n#run this model so we have ~4000 samples to calculate mean and SD\nmodel2 &lt;- update(model,\n                 parameters.to.save = params2,\n                 n.iter = 1335,\n                 parallel = TRUE)\n\n# Extract summary stats of bray ------------------------------------------------\n\n#get a summary of this model and the parameters we saved (bray)\nsum &lt;- summary(model2$samples)\n\n#pull out mean and SD values from that summary\nstats &lt;- as.data.frame(sum$statistics) %&gt;%\n  rownames_to_column(var = 'parm') %&gt;%\n  filter(parm != \"deviance\") %&gt;%\n  #re-connect these values with their transect and year IDs\n  separate(parm, \n           into = c(\"transect\", \"year\"),\n           sep = \",\") %&gt;%\n  mutate(transect = str_sub(transect, 6, (nchar(transect))),\n         year = str_sub(year, 1, (nchar(year)-1))) %&gt;%\n  mutate(transect = as.numeric(transect),\n         year = as.numeric(year)) %&gt;%\n  #select only the variables of interest\n  dplyr::select(transect, year, Mean, SD)\n\nWe have saved this dataframe in the MSAM tutorial folder.\nNow we have a nice dataframe with mean (\\(\\bar{d}_{t,y}\\)) and standard deviation (\\(\\hat{\\sigma}(\\bar{d}_{t,y})\\)) for the Bray-Curtis dissimilarity calculated for each site along its time series. You will notice that the year value starts with year 2 and this is because this is the first year in which we have two community values to compare. and variance\n\nstr(stats)\n\n'data.frame':   12 obs. of  4 variables:\n $ transect: num  1 2 3 1 2 3 1 2 3 1 ...\n $ year    : num  2 2 2 3 3 3 4 4 4 5 ...\n $ Mean    : num  0.664 0.638 0.616 0.486 0.505 ...\n $ SD      : num  0.0266 0.026 0.0252 0.0362 0.0372 ...\n\n\nWe can also look at how Bray-Curtis dissimilarity changes through time for each of our transects in our simulated datasets.\n\nlabels &lt;- c(\"Transect 1\", \"Transect 2\", \"Transect 3\")\nnames(labels) &lt;- c('1', '2', '3')\n\nggplot(stats) +\n  geom_ribbon(aes(x = year, ymin = Mean-SD, ymax = Mean+SD), alpha = 0.6) +\n  geom_line(aes(x = year, y = Mean)) +\n  facet_grid(~transect, labeller = labeller(transect = labels)) +\n  theme_bw() +\n  theme(strip.background = element_rect(fill = \"white\")) +\n  labs(x = \"Year\", y = \"Bray-Curtis dissimilarity \\n (Posterior mean and SD)\")\n\n\n\n\n\n\n2.2.3 Next: Evaluating community stability in relation to environmental variables\nNext we will take the mean and standard deviation of these community change values and incorporate them into a regression with environmental covariates to examine how these covariates shape communities.\n\n\n\n\nBaselga, Andres, David Orme, Sebastien Villeger, Julien De Bortoli, Fabien Leprieur, and Maxime Logez. 2021. Betapart: Partitioning Beta Diversity into Turnover and Nestedness Components. https://CRAN.R-project.org/package=betapart.\n\n\nHallett, Lauren M., Sydney K. Jones, A. Andrew M. MacDonald, Matthew B. Jones, Dan F. B. Flynn, Julie Ripplinger, Peter Slaughter, Corinna Gries, and Scott L. Collins. 2016. “Codyn: Anrpackage of Community Dynamics Metrics.” Edited by Timothée Poisot. Methods in Ecology and Evolution 7 (10): 1146–51. https://doi.org/10.1111/2041-210x.12569.\n\n\nOksanen, Jari, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt, Pierre Legendre, Dan McGlinn, Peter R. Minchin, et al. 2020. Vegan: Community Ecology Package. https://CRAN.R-project.org/package=vegan."
  },
  {
    "objectID": "03_community-stability-environment.html#model-formulation",
    "href": "03_community-stability-environment.html#model-formulation",
    "title": "3  Evaluating community stability in relation to environmental variables",
    "section": "3.1 Model formulation",
    "text": "3.1 Model formulation\nOur diversity metrics are functionally proportions, so the data have domain \\([0,1]\\). We can model proportions with a beta distribution, where the mean dissimilarity metric calculated in the previous step, \\(\\bar{d}_{t,y}\\), is beta distributed:\n\\(\\bar{d}_{t,y} \\sim Beta(\\alpha_{t,y}, \\beta_{t,y})\\)\nWe follow other beta regression approaches (Irvine, Rodhouse, and Keren (2016); Ferrari and Cribari-Neto (2004)) to define the parameters \\(\\alpha_{t,y}\\) and \\(\\beta_{t,y}\\) as:\n\\(\\alpha_{t,y} = \\delta_{t,y}\\phi_{t,y}\\)\n\\(\\beta_{t,y} = (1 - \\delta_{t,y})\\phi_{t,y}\\)\nIn these equations, \\(\\delta_{t,y}\\) is the mean or expected value of the stability index, \\(\\bar{d}_{t,y}\\) and \\(\\phi_{t,y}\\) is a precision-type term. When \\(\\phi_{t,y}\\) is larger, the variance for \\(\\bar{d}_{t,y}\\) (\\(Var(\\bar{d}_{t,y})\\)) is smaller. \\(\\phi_{t,y}\\) is defined as:\n\\(\\phi_{t,y} = \\frac{\\delta_{t,y}(1-\\delta_{t,y})}{Var(\\bar{d}_{t,y})}-1\\)\nand \\(Var(\\bar{d}_{t,y})\\) includes both known variance from the imperfect detection model, \\(\\hat{\\sigma}^2(\\bar{d}_{t,y})\\), and unknown “process” variance, \\(\\sigma^2_{P}\\):\n\\(Var(\\bar{d}_{t,y}) = \\hat{\\sigma}^2(\\bar{d}_{t,y}) + \\sigma^2_{P}\\)\nWe set a uniform prior for the process variance, \\(\\sigma^2_{P}\\) with an upper limit that ensures that \\(\\alpha_{t,y} &gt; 0\\) and \\(\\beta_{t,y} &gt; 0\\).\nThe mean (expected) stability index, \\(\\delta_{t,y}\\), is defined via a regression model:\n\\(logit(\\delta_{t,y}) = \\beta_{0,t} + \\sum_{j =1}^J\\beta_jZ_{j,t,y}\\)\nIn this regression, \\(\\beta_{0,t}\\) varies by a spatial factor by including a spatial random effect with priors that are hierarchically centered around a coarser spatial level, which is given a prior that varies around an overall community intercept (Ogle and Barber 2020). The coefficients \\(\\beta_1\\), \\(\\beta_2\\)… \\(\\beta_J\\) denote the effects of an antecedent covariate, \\(Z_{j,t,y}\\) for j = 1, 2, …,J covariates. Each covariate \\(Z_{j,t,y}\\) is the weighted average of the current value for that covariate at time y and a defined number of past values for that covariate preceding time y. We divided these into either seasonal or yearly values for that covariate (e.g., spring temperature, yearly plant biomass). The weight (“importance weight”) of each of these values, m, in the overall calculation of \\(Z_{j,t,y}\\), \\(w_{j,m}\\), is estimated by the model using the stochastic antecedent modeling framework (Ogle et al. 2015). In this modeling framework, each \\(w_{j,m}\\) is estimated using a Dirichlet prior so that the sum across all weights for that covariate equals one and more important time periods, m get higher importance weights. Thus, when a covariate effect, \\(\\beta_j\\) is significant, the weights for each time lag for that covariate informs over which timescale(s) that covariate influences community change.\n\n3.1.1 The model translated to JAGS code\nBelow is example JAGS code for the model specified above:\n\nmodel{\n  \n  for(i in 1:n.data){\n    \n    #-------------------------------------## \n    # Likelihood ###\n    #-------------------------------------##\n    \n    #d is dissimilarity and is proportional, so beta distribution works here\n    d[i] ~ dbeta(alpha[i], beta[i])\n      \n    #var.process is scalar but could be made dependent on site/other variables\n    #phi incorporates mu (mean estimate), var.estimate (which is from\n    #\"data\" on standard deviation (squared) from the original detection \n    #correction model) \n    #and var.process is something we're trying to estimate,\n    #basically, the rest of the variation not accounted for\n    phi[i] &lt;- (((1-mu[i])*mu[i])/(var.estimate[i] + var.process))-1\n\n    #alpha and beta are based on mu and phi values\n    #sometimes these values send alpha and beta outside\n    #the domain, so we have extra code below to get them to\n    #stay where they belong\n    alphaX[i] &lt;- mu[i] * phi[i]\n    betaX[i] &lt;- (1 - mu[i]) * phi[i]\n    \n    #here is where we get alpha and beta to stay in their\n    #domain\n    alpha[i] &lt;- max(0.01, alphaX[i])\n    beta[i] &lt;- max(0.01, betaX[i])\n    \n    #to get a good estimate of a prior for var.process, we\n    #track the difference between these two values for each\n    #data point\n    diff[i] &lt;- (1-mu[i])*mu[i] - var.estimate[i]\n\n    #Regression of mu, which is dependent on a hierrarchically-centered\n    #site random effect and the weighted antecedent effects of two covariates,\n    #plant biomass and temperature\n      logit(mu[i]) &lt;- b0.site[Site.ID[i]] +\n        b[1]*AntPlant[i] +\n        b[2]*AntTemp[i]\n      \n      #-------------------------------------## \n      # SAM summing ###\n      #-------------------------------------##\n      \n      #summing the antecedent values\n      AntPlant[i] &lt;- sum(PlantTemp[i,]) #summing across the total number of antecedent years\n      AntTemp[i] &lt;- sum(TempTemp[i,]) #summing across the total num of antecedent months\n\n      #Generating each year's weight to sum above\n      for(t in 1:n.plantlag){ #number of time steps we're going back in the past\n        PlantTemp[i,t] &lt;- Plant[i,t]*wA[t] \n      \n        #imputing missing data\n        Plant[i,t] ~ dnorm(mu.plant, tau.plant)\n      }\n        \n      #generating each month's weight to sum above\n      for(t in 1:n.templag){ #number of time steps we're going back in the past\n        TempTemp[i,t] &lt;- Temp[i,t]*wB[t] \n\n        #missing data\n        Temp[i,t] ~ dnorm(mu.temp, tau.temp)\n      }\n      \n      #-------------------------------------## \n      # Goodness of fit parameters ###\n      #-------------------------------------##\n      # \n      #replicated data\n      d.rep[i] ~ dbeta(alpha[i], beta[i])\n      # \n      #residuals\n      resid[i] &lt;- d[i] - mu[i]\n \n  }\n  \n  #-------------------------------------## \n  # Priors ###\n  #-------------------------------------##\n  \n  # ANTECEDENT CLIMATE PRIORS\n  #Sum of the weights for lag\n  sumA &lt;- sum(deltaA[]) #all the plant weights\n  \n  #Employing \"delta trick\" to give vector of weights dirichlet priors\n  #this is doing the dirichlet in two steps \n  #see Ogle et al. 2015 SAM model paper in Ecology Letters\n  for(t in 1:n.plantlag){ #for the total number of lags\n    #the weights for kelp - getting the weights to sum to 1\n    wA[t] &lt;- deltaA[t]/sumA\n    #and follow a relatively uninformative gamma prior\n    deltaA[t] ~ dgamma(1,1)\n    \n    #to look at how weights accumulate through time\n    cumm.plantwt[t] &lt;- sum(wA[1:t])\n  }\n  \n  #Sum of the weights for temp lag\n  sumB &lt;- sum(deltaB[]) #all the temp weights\n  \n  #Employing \"delta trick\" to give vector of weights dirichlet priors\n  #this is doing the dirichlet in two steps \n  #see Ogle et al. 2015 SAM model paper in Ecology Letters\n  for(t in 1:n.templag){ #for the total number of lags\n    #the weights for kelp - getting the weights to sum to 1\n    wB[t] &lt;- deltaB[t]/sumB\n    #and follow a relatively uninformative gamma prior\n    deltaB[t] ~ dgamma(1,1)\n    \n    #to look at cummulative weigths through time\n    cumm.tempwt[t] &lt;- sum(wB[1:t])\n  }\n  \n  #BETA PRIORS\n  #HIERARCHICAL STRUCTURE PRIORS\n  #hierarchical centering of sites on b0\n   for(s in 1:n.sites){\n     b0.site[s] ~ dnorm(b0, tau.site)\n   }\n  \n  #overall intercept gets relatively uninformative prior\n  b0 ~ dnorm(0, 1E-2)\n  \n  #for low # of levels, from Gelman paper - define sigma\n  # as uniform and then precision in relation to this sigma\n  sig.site ~ dunif(0, 10)\n  tau.site &lt;- 1/pow(sig.site,2)\n  \n  #covariate effects - again get relatively uninformative priors\n  for(i in 1:2){\n    b[i] ~ dnorm(0, 1E-2)\n  }\n  \n  #PRior for process error\n  var.process ~ dunif(0, min(diff[]))\n\n\n  #MISSING DATA PRIORS\n  mu.plant ~ dunif(-10, 10)\n  sig.plant ~ dunif(0, 20)\n  tau.plant &lt;- pow(sig.plant, -2)\n  mu.temp ~ dunif(-10, 10)\n  sig.temp ~ dunif(0, 20)\n  tau.temp &lt;- pow(sig.temp, -2)\n  \n}"
  },
  {
    "objectID": "03_community-stability-environment.html#wrapping-up",
    "href": "03_community-stability-environment.html#wrapping-up",
    "title": "3  Evaluating community stability in relation to environmental variables",
    "section": "3.3 Wrapping up",
    "text": "3.3 Wrapping up\nFor all models, you will want to be able to describe some kind of goodness-of-fit metric. We do this by replicating data in the model (e.g., d.rep in the model above) and then comparing the relationship between replicated data and observed data using a simple linear regression (Conn et al. 2018). You can find an example of this process in the code for the paper.\n\n\n\n\nConn, Paul B., Devin S. Johnson, Perry J. Williams, Sharon R. Melin, and Mevin B. Hooten. 2018. “A Guide to Bayesian Model Checking for Ecologists.” Ecological Monographs 88 (4): 526–42. https://doi.org/10.1002/ecm.1314.\n\n\nFerrari, Silvia, and Francisco Cribari-Neto. 2004. “Beta Regression for Modelling Rates and Proportions.” Journal of Applied Statistics 31 (7): 799–815. https://doi.org/10.1080/0266476042000214501.\n\n\nIrvine, Kathryn M., T. J. Rodhouse, and Ilai N. Keren. 2016. “Extending Ordinal Regression with a Latent Zero-Augmented Beta Distribution.” Journal of Agricultural, Biological and Environmental Statistics 21 (4): 619–40. https://doi.org/10.1007/s13253-016-0265-2.\n\n\nOgle, Kiona, and Jarrett J. Barber. 2020. “Ensuring Identifiability in Hierarchical Mixed Effects Bayesian Models.” Ecological Applications 30 (7): e02159. https://doi.org/10.1002/eap.2159.\n\n\nOgle, Kiona, Jarrett J. Barber, Greg A. Barron-Gafford, Lisa Patrick Bentley, Jessica M. Young, Travis E. Huxman, Michael E. Loik, and David T. Tissue. 2015. “Quantifying Ecological Memory in Plant and Ecosystem Processes.” Edited by Elsa Cleland. Ecology Letters 18 (3): 221–35. https://doi.org/10.1111/ele.12399."
  },
  {
    "objectID": "03_community-stability-environment.html#the-model-in-action",
    "href": "03_community-stability-environment.html#the-model-in-action",
    "title": "3  Evaluating community stability in relation to environmental variables",
    "section": "3.2 The model in action",
    "text": "3.2 The model in action\nBecause we have greatly reduced the dimensionality of our community dataset by deriving a change metric for each site in each year, y to the next year y+1, the models run efficiently enough that we can use one of the case studies from the paper in this tutorial. We will demonstrate the utility of this model for the SBC Fish LTER dataset. This LTER site also has yearly data on kelp biomass and bottom temperature data from data loggers, which we used as environmental covariates in this model.\nThis dataset has:\n\n43 communities (survey transects) which have change data for\n11 - 22 years, depending on the site and we calculated\nBray-Curtis dissimilarity for this count dataset\n11 seasons of temperature data and\n6 years of plant data as covariates\n\nIn this dataset, we are evaluating how Bray-Curtis dissimilarity through time is shaped by the covariates of kelp biomass and temperature.\nAgain, to run the model in R and JAGS, we will need:\n\nThe model file\nThe data list\nA script to wrap JAGS in R\n\nYou can find all of these, along with the tidy data and script used to prep the data list for this example, in the SAM tutorial folder\n\n3.2.1 Running the model\n\n3.2.1.1 The model file\nYou will need to provide a path to the model file (which is its own R script, written in JAGS/BUGS language, so it won’t actually run in R). You can find ours here. You will see that we define the path to this model in our model running script below.\n\n\n3.2.1.2 The data list\nTo run the model, we will need to provide JAGS with a data list, which you can find here. We have code on how to prepare the data list here.\n\ndata_list &lt;- readRDS(here('tutorials',\n                          'SAM',\n                          'data',\n                          \"model_inputs\",\n                          \"SAM_input_data.RDS\"))\n\nstr(data_list)\n\nList of 9\n $ n.data      : int 856\n $ n.sites     : int 11\n $ Site.ID     : Named num [1:856] 4 4 4 5 5 5 5 5 5 5 ...\n  ..- attr(*, \"names\")= chr [1:856] \"SITE1\" \"SITE2\" \"SITE3\" \"SITE4\" ...\n $ d           : num [1:856] 0.517 0.521 0.51 0.416 0.401 ...\n $ var.estimate: num [1:856] 0.01623 0.0148 0.0161 0.00984 0.0099 ...\n $ n.plantlag  : int 6\n $ Plant       : num [1:856, 1:6] -0.7964 -0.7517 -0.8167 0.0222 -0.8167 ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:6] \"DRY_GM2\" \"DRY_GM2_l1\" \"DRY_GM2_l2\" \"DRY_GM2_l3\" ...\n $ n.templag   : int 11\n $ Temp        : num [1:856, 1:11] NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"dimnames\")=List of 2\n  .. ..$ : NULL\n  .. ..$ : chr [1:11] \"TEMP_C\" \"TEMP_C_l1\" \"TEMP_C_l2\" \"TEMP_C_l3\" ...\n\n\nAs you can see, this data list includes indexing numbers, vectors, matrices, and arrays to pass to JAGS.\n\n\n3.2.1.3 The script to run the model\nJust like with the imperfect detection model, we’ll run the model using the jagsUI wrapper package. You can find this script here, and the general code to run a JAGS model is provided here:\n\n# Load packages ---------------------------------------------------------------\n\n# Load packages, here and tidyverse for coding ease, \npackage.list &lt;- c(\"here\", \"tidyverse\", #general packages for data input/manipulation\n                  \"jagsUI\", #to run JAGS models\n                  'mcmcplots', #to look at trace plots\n                  \"coda\") #to evaluate convergence\n                   \n\n## Installing them if they aren't already on the computer\nnew.packages &lt;- package.list[!(package.list %in% \n                                 installed.packages()[,\"Package\"])]\nif(length(new.packages)) install.packages(new.packages)\n\n## And loading them\nfor(i in package.list){library(i, character.only = T)}\n\n\n# Load data ---------------------------------------------------------------\n\ndata_list &lt;- readRDS(here('tutorials',\n                          'SAM',\n                          'data',\n                          \"model_inputs\",\n                          \"SAM_input_data.RDS\"))\n\n\n# Define model path -------------------------------------------------------\n\nmodel &lt;- here('tutorials',\n              'SAM',\n              'code',\n              'SAM_model.R')\n\n# Parameters to save ------------------------------------------------------\n\n#these parameters we can track to assess convergence\nparams &lt;- c('b0.site', #site-level intercepts\n            'b0', #overall intercept\n            'b', #covariate effects\n            'wA', #plant biomass weights vector\n            'wB', #temperature weights\n            'sig.site', #sd of site effects\n            'var.process') #unknown variance\n\n# JAGS model --------------------------------------------------------------\n\nmod &lt;- jagsUI::jags(data = data_list,\n                    inits = NULL,\n                    model.file = model,\n                    parameters.to.save = params,\n                    parallel = TRUE,\n                    n.chains = 3,\n                    n.burnin =1500,\n                    n.iter = 5000,\n                    DIC = TRUE)\n\n\n# Check convergence -------------------------------------------------------\n# \nmcmcplot(mod$samples)\n# \ngelman.diag(mod$samples, multivariate = F)\n\nAgain, depending on your computer and/or datasets, you may need to re-run this model with initial values for root nodes and use cloud computing to run this model.\n\n\n\n3.2.2 Model results\nOnce you have a resulting model file (which could be quite large), you can generate a summary of it:\n\nsum &lt;- summary(mod$samples)\n\nWe can look at estimated values from this summary to assess how plant biomass and temperature impact SBC LTER fish communities.\n\n3.2.2.1 Covariate effects\n\n#pull median and 95% BCI out of the summary file:\nbetas &lt;- as.data.frame(sum$quantiles) %&gt;%\n  #get parameter names to be a column\n    rownames_to_column(var = \"parm\") %&gt;%\n  #select only the covariate effect betas\n    filter(str_detect(parm, \"b\")) %&gt;%\n    filter(!str_detect(parm, \"b0\")) \n\n#plot these median and 95% BCI values\nggplot(betas, aes(x = `50%`, y = parm)) +\n  geom_vline(xintercept = 0, linetype = 2, alpha = 0.4) +\n  geom_pointrange(aes(x = `50%`,\n                      y = parm, \n                      xmin = `2.5%`,\n                      xmax = `97.5%`),\n                  size = 0.4) +\n  scale_y_discrete(labels = c(\"Kelp biomass\", \"Temperature\")) + \n  labs(x = \"Covariate effect \\n (Median and 95% BCI)\",\n       y = \"\") +\n  theme_bw()\n\n\n\n\nThis figure suggests that there is a clear effect of temperature, but not plant biomass, on community change. Higher temperatures lead to higher community change. We can then look at which seasons drive this temperature effect:\n\n#pull the median and 95% BCI weights for temperature out of the model summary file\nfish_tweights &lt;- as.data.frame(sum$quantiles) %&gt;%\n  rownames_to_column(var = \"parm\") %&gt;%\n  filter(str_detect(parm, \"wB\")) %&gt;%\n  #indicate which type of season they're in\n  mutate(season = case_when(parm %in% c(\"wB[1]\", \"wB[3]\", \"wB[5]\",\n                                        'wB[7]', 'wB[9]','wB[11]') ~ \"Warm\",\n                            parm %in% c(\"wB[2]\", \"wB[4]\", 'wB[6]',\n                                        'wB[8]', 'wB[10]') ~ \"Cold\")) %&gt;%\n  #get the years into the past for each of these seasons\n  mutate(year = case_when(parm == \"wB[1]\" ~ 0,\n                          parm %in% c(\"wB[2]\", 'wB[3]') ~ 1,\n                          parm %in% c('wB[4]', 'wB[5]') ~ 2,\n                          parm %in% c(\"wB[6]\", 'wB[7]') ~ 3,\n                          parm %in% c(\"wB[8]\", 'wB[9]') ~ 4,\n                          parm %in% c(\"wB[10]\", 'wB[11]') ~ 5,\n                          TRUE ~ NA_real_)) %&gt;% \n  complete(season, year) \n\n#indicate colors for seasons\nwarmcol &lt;- '#d8b365'\ncoldcol &lt;- '#5ab4ac'\n\n#plot these median and 95% BCI values. \nfish_tweights %&gt;%\n  ggplot(aes(x = year, y = `50%`, color = season, shape = season)) +\n  geom_hline(yintercept = 1/11, linetype = 2, linewidth = 0.1) +\n  geom_pointrange(aes(ymin = `2.5%`, ymax = `97.5%`),\n                  position = position_dodge(width = 0.5), size = 0.4) +\n  scale_x_continuous(breaks = c(0, 1, 2, 3, 4, 5)) +\n  scale_color_manual(values = c(\"Warm\" = warmcol, \"Cold\" = coldcol),\n                     breaks = c(\"Warm\", \"Cold\")) +\n  scale_shape_manual(values = c(\"Warm\" = 17, \"Cold\" = 16),\n                     breaks = c(\"Warm\", \"Cold\")) +\n  labs(x = \"Years into the past\",\n       y = \"Importance weight \\n (Median and 95% BCI)\",\n       shape = \"\", color = \"\") +\n  theme(legend.position = c(0.92, 1.1)) +\n  theme_bw()\n\n\n\n\nThe dashed line indicates the values of importance weights if they were all equal (their prior weights). Any values clearly above this line indicate more important seasons for the temperature effect. There is a fairly clear effect of the previous cold season on community change, with less but still slight effects of the current warm season and every other cold season in the past. This figure suggests that when the previous cold season is relatively warm, there is more community change."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baselga, Andres, David Orme, Sebastien Villeger, Julien De Bortoli,\nFabien Leprieur, and Maxime Logez. 2021. Betapart: Partitioning Beta\nDiversity into Turnover and Nestedness Components. https://CRAN.R-project.org/package=betapart.\n\n\nConn, Paul B., Devin S. Johnson, Perry J. Williams, Sharon R. Melin, and\nMevin B. Hooten. 2018. “A Guide to Bayesian Model Checking for\nEcologists.” Ecological Monographs 88 (4): 526–42. https://doi.org/10.1002/ecm.1314.\n\n\nDorazio, Robert M., Andrew Royle, Bo Soderstrom, and Anders Glimskar.\n2006. “Estimating Species Richness and Accumulation by Modeling\nSpecies Occurence and Detectability.” Ecology 87 (4):\n842–54. https://doi.org/10.1890/0012-9658(2006)87[842:ESRAAB]2.0.CO;2.\n\n\nFerrari, Silvia, and Francisco Cribari-Neto. 2004. “Beta\nRegression for Modelling Rates and Proportions.” Journal of\nApplied Statistics 31 (7): 799–815. https://doi.org/10.1080/0266476042000214501.\n\n\nHallett, Lauren M., Sydney K. Jones, A. Andrew M. MacDonald, Matthew B.\nJones, Dan F. B. Flynn, Julie Ripplinger, Peter Slaughter, Corinna\nGries, and Scott L. Collins. 2016. “Codyn: Anrpackage of Community\nDynamics Metrics.” Edited by Timothée Poisot. Methods in\nEcology and Evolution 7 (10): 1146–51. https://doi.org/10.1111/2041-210x.12569.\n\n\nIrvine, Kathryn M., T. J. Rodhouse, and Ilai N. Keren. 2016.\n“Extending Ordinal Regression with a Latent Zero-Augmented Beta\nDistribution.” Journal of Agricultural, Biological and\nEnvironmental Statistics 21 (4): 619–40. https://doi.org/10.1007/s13253-016-0265-2.\n\n\nOgle, Kiona, and Jarrett J. Barber. 2020. “Ensuring\nIdentifiability in Hierarchical Mixed Effects Bayesian Models.”\nEcological Applications 30 (7): e02159. https://doi.org/10.1002/eap.2159.\n\n\nOgle, Kiona, Jarrett J. Barber, Greg A. Barron-Gafford, Lisa Patrick\nBentley, Jessica M. Young, Travis E. Huxman, Michael E. Loik, and David\nT. Tissue. 2015. “Quantifying Ecological Memory in Plant and\nEcosystem Processes.” Edited by Elsa Cleland. Ecology\nLetters 18 (3): 221–35. https://doi.org/10.1111/ele.12399.\n\n\nOksanen, Jari, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt,\nPierre Legendre, Dan McGlinn, Peter R. Minchin, et al. 2020. Vegan:\nCommunity Ecology Package. https://CRAN.R-project.org/package=vegan."
  }
]